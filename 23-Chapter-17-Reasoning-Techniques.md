------

# Chapter 17: Reasoning Techniques | <mark>ç¬¬ 17 ç« ï¼šæ¨ç†æŠ€æœ¯</mark>

This chapter delves into advanced reasoning methodologies for intelligent agents, focusing on multi-step logical inferences and problem-solving. These techniques go beyond simple sequential operations, making the agent's internal reasoning explicit. This allows agents to break down problems, consider intermediate steps, and reach more robust and accurate conclusions.  A core principle among these advanced methods is the allocation of increased computational resources during inference. This means granting the agent, or the underlying LLM, more processing time or steps to process a query and generate a response. Rather than a quick, single pass, the agent can engage in iterative refinement, explore multiple solution paths, or utilize external tools. This extended processing time during inference often significantly enhances accuracy, coherence, and robustness, especially for complex problems requiring deeper analysis and deliberation.

<mark>æœ¬ç« æ·±å…¥æ¢è®¨äº†æ™ºèƒ½ä½“çš„å…ˆè¿›æ¨ç†æ–¹æ³•ï¼Œé‡ç‚¹ä»‹ç»å¤šæ­¥é€»è¾‘æ¨ç†å’Œé—®é¢˜è§£å†³æŠ€æœ¯ã€‚è¿™äº›æŠ€æœ¯è¶…è¶Šäº†ç®€å•çš„é¡ºåºæ“ä½œï¼Œä½¿æ™ºèƒ½ä½“çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹æ›´åŠ æ˜ç¡®ã€‚è¿™ä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿåˆ†è§£é—®é¢˜ã€è€ƒè™‘ä¸­é—´æ­¥éª¤ï¼Œå¹¶å¾—å‡ºæ›´åŠ ç¨³å¥å’Œå‡†ç¡®çš„ç»“è®ºã€‚åœ¨è¿™äº›å…ˆè¿›æ–¹æ³•ä¸­ï¼Œä¸€ä¸ªæ ¸å¿ƒåŸåˆ™æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­åˆ†é…æ›´å¤šçš„è®¡ç®—èµ„æºã€‚è¿™æ„å‘³ç€ç»™äºˆæ™ºèƒ½ä½“æˆ–åº•å±‚ LLM æ›´å¤šçš„å¤„ç†æ—¶é—´æˆ–æ­¥éª¤æ¥å¤„ç†æŸ¥è¯¢å¹¶ç”Ÿæˆå“åº”ã€‚æ™ºèƒ½ä½“å¯ä»¥è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€æ¢ç´¢å¤šç§è§£å†³æ–¹æ¡ˆè·¯å¾„æˆ–åˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼Œè€Œä¸æ˜¯è¿›è¡Œå¿«é€Ÿçš„å•æ¬¡å¤„ç†ã€‚è¿™ç§åœ¨æ¨ç†è¿‡ç¨‹ä¸­å»¶é•¿çš„å¤„ç†æ—¶é—´é€šå¸¸èƒ½æ˜¾è‘—æé«˜å‡†ç¡®æ€§ã€è¿è´¯æ€§å’Œç¨³å¥æ€§ï¼Œå°¤å…¶å¯¹äºéœ€è¦æ·±å…¥åˆ†æå’Œæ€è€ƒçš„å¤æ‚é—®é¢˜ã€‚</mark>

## Practical Applications & Use Cases | <mark>å®é™…åº”ç”¨ä¸ä½¿ç”¨æ¡ˆä¾‹</mark>

Practical applications include:

<mark>å®é™…åº”ç”¨åŒ…æ‹¬ï¼š</mark>

â—**Complex Question Answering**: Facilitating the resolution of multi-hop queries, which necessitate the integration of data from diverse sources and the execution of logical deductions, potentially involving the examination of multiple reasoning paths, and benefiting from extended inference time to synthesize information.

<mark>â—**å¤æ‚é—®ç­”**ï¼šä¿ƒè¿›å¤šè·³æŸ¥è¯¢çš„è§£å†³ï¼Œè¿™ç±»æŸ¥è¯¢éœ€è¦æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„æ•°æ®å¹¶æ‰§è¡Œé€»è¾‘æ¨ç†ï¼Œå¯èƒ½æ¶‰åŠæ£€æŸ¥å¤šæ¡æ¨ç†è·¯å¾„ï¼Œå¹¶å¾—ç›Šäºæ›´é•¿çš„æ¨ç†æ—¶é—´æ¥ç»¼åˆä¿¡æ¯ã€‚</mark>

â—**Mathematical Problem Solving**: Enabling the division of mathematical problems into smaller, solvable components, illustrating the step-by-step process, and employing code execution for precise computations, where prolonged inference enables more intricate code generation and validation.

<mark>â—**æ•°å­¦é—®é¢˜è§£å†³**ï¼šå°†æ•°å­¦é—®é¢˜åˆ†è§£ä¸ºæ›´å°ã€å¯è§£å†³çš„ç»„æˆéƒ¨åˆ†ï¼Œå±•ç¤ºé€æ­¥è§£å†³è¿‡ç¨‹ï¼Œå¹¶ä½¿ç”¨ä»£ç æ‰§è¡Œè¿›è¡Œç²¾ç¡®è®¡ç®—ï¼Œå…¶ä¸­é•¿æ—¶é—´çš„æ¨ç†èƒ½å¤Ÿæ”¯æŒæ›´å¤æ‚çš„ä»£ç ç”Ÿæˆå’ŒéªŒè¯ã€‚</mark>

â—**Code Debugging and Generation**: Supporting an agent's explanation of its rationale for generating or correcting code, pinpointing potential issues sequentially, and iteratively refining the code based on test results (Self-Correction), leveraging extended inference time for thorough debugging cycles.

<mark>â—**ä»£ç è°ƒè¯•ä¸ç”Ÿæˆ**ï¼šæ”¯æŒæ™ºèƒ½ä½“å¯¹å…¶ç”Ÿæˆæˆ–ä¿®æ­£ä»£ç çš„æ¨ç†ä¾æ®è¿›è¡Œè§£é‡Šï¼Œé¡ºåºè¯†åˆ«æ½œåœ¨é—®é¢˜ï¼Œå¹¶æ ¹æ®æµ‹è¯•ç»“æœè¿­ä»£ä¼˜åŒ–ä»£ç ï¼ˆè‡ªæˆ‘ä¿®æ­£ï¼‰ï¼Œåˆ©ç”¨æ‰©å±•çš„æ¨ç†æ—¶é—´è¿›è¡Œå½»åº•çš„è°ƒè¯•å‘¨æœŸã€‚</mark>

â—**Strategic Planning**: Assisting in the development of comprehensive plans through reasoning across various options, consequences, and preconditions, and adjusting plans based on real-time feedback (ReAct), where extended deliberation can lead to more effective and reliable plans.

<mark>â—**æˆ˜ç•¥è§„åˆ’**ï¼šé€šè¿‡æ¨ç†å„ç§é€‰é¡¹ã€ç»“æœå’Œå…ˆå†³æ¡ä»¶æ¥ååŠ©åˆ¶å®šå…¨é¢è®¡åˆ’ï¼Œå¹¶æ ¹æ®å®æ—¶åé¦ˆï¼ˆReActï¼‰è°ƒæ•´è®¡åˆ’ï¼Œå…¶ä¸­æ·±å…¥çš„æ€è€ƒå¯ä»¥å¯¼è‡´æ›´æœ‰æ•ˆå’Œå¯é çš„è®¡åˆ’ã€‚</mark>

â—**Medical Diagnosis**: Aiding an agent in systematically assessing symptoms, test outcomes, and patient histories to reach a diagnosis, articulating its reasoning at each phase, and potentially utilizing external instruments for data retrieval (ReAct). Increased inference time allows for a more comprehensive differential diagnosis.

<mark>â—**åŒ»ç–—è¯Šæ–­**ï¼šå¸®åŠ©æ™ºèƒ½ä½“ç³»ç»Ÿè¯„ä¼°ç—‡çŠ¶ã€æ£€æŸ¥ç»“æœå’Œæ‚£è€…ç—…å²ä»¥åšå‡ºè¯Šæ–­ï¼Œåœ¨æ¯ä¸ªé˜¶æ®µé˜è¿°å…¶æ¨ç†è¿‡ç¨‹ï¼Œå¹¶å¯èƒ½åˆ©ç”¨å¤–éƒ¨å·¥å…·è¿›è¡Œæ•°æ®æ£€ç´¢ï¼ˆReActï¼‰ã€‚å¢åŠ æ¨ç†æ—¶é—´å¯ä»¥å®ç°æ›´å…¨é¢çš„é‰´åˆ«è¯Šæ–­ã€‚</mark>

â—**Legal Analysis**: Supporting the analysis of legal documents and precedents to formulate arguments or provide guidance, detailing the logical steps taken, and ensuring logical consistency through self-correction. Increased inference time allows for more in-depth legal research and argument construction.

<mark>â—**æ³•å¾‹åˆ†æ**ï¼šæ”¯æŒå¯¹æ³•å¾‹æ–‡ä»¶å’Œåˆ¤ä¾‹çš„åˆ†æï¼Œä»¥åˆ¶å®šè®ºç‚¹æˆ–æä¾›æŒ‡å¯¼ï¼Œè¯¦ç»†è¯´æ˜æ‰€é‡‡å–çš„é€»è¾‘æ­¥éª¤ï¼Œå¹¶é€šè¿‡è‡ªçº æ­£ï¼ˆself-correctionï¼‰ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚å¢åŠ æ¨ç†æ—¶é—´å¯ä»¥è¿›è¡Œæ›´æ·±å…¥çš„æ³•å¾‹ç ”ç©¶å’Œè®ºç‚¹æ„å»ºã€‚</mark>

## Reasoning techniques
## <mark>æ¨ç†æŠ€å·§</mark>

To start, let's delve into the core reasoning techniques used to enhance the problem-solving abilities of AI models.

<mark>é¦–å…ˆï¼Œæˆ‘ä»¬æ·±å…¥æ¢ç©¶æ—¨åœ¨æå‡ AI æ¨¡å‹é—®é¢˜è§£å†³èƒ½åŠ›çš„æ ¸å¿ƒæ¨ç†æŠ€å·§ã€‚</mark>

**Chain-of-Thought (CoT)** prompting significantly enhances LLMs' complex reasoning abilities by mimicking a step-by-step thought process (see Fig. 1). Instead of providing a direct answer, CoT prompts guide the model to generate a sequence of intermediate reasoning steps. This explicit breakdown allows LLMs to tackle complex problems by decomposing them into smaller, more manageable sub-problems. This technique markedly improves the model's performance on tasks requiring multi-step reasoning, such as arithmetic, common sense reasoning, and symbolic manipulation. A primary advantage of CoT is its ability to transform a difficult, single-step problem into a series of simpler steps, thereby increasing the transparency of the LLM's reasoning process. This approach not only boosts accuracy but also offers valuable insights into the model's decision-making, aiding in debugging and comprehension. CoT can be implemented using various strategies, including offering few-shot examples that demonstrate step-by-step reasoning or simply instructing the model to "think step by step." Its effectiveness stems from its ability to guide the model's internal processing toward a more deliberate and logical progression. As a result, Chain-of-Thought has become a cornerstone technique for enabling advanced reasoning capabilities in contemporary LLMs. This enhanced transparency and breakdown of complex problems into manageable sub-problems is particularly important for autonomous agents, as it enables them to perform more reliable and auditable actions in complex environments.

<mark>**æ€ç»´é“¾ (CoT)** æç¤ºé€šè¿‡æ¨¡ä»¿é€æ­¥æ€è€ƒçš„è¿‡ç¨‹ï¼ˆå‚è§å›¾ 1ï¼‰ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›ã€‚CoT æç¤ºå¹¶éç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œè€Œæ˜¯å¼•å¯¼æ¨¡å‹ç”Ÿæˆä¸€ç³»åˆ—ä¸­é—´æ¨ç†æ­¥éª¤ã€‚è¿™ç§æ¸…æ™°çš„æ‹†è§£ä½¿ LLM èƒ½å¤Ÿå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“å¤„ç†çš„å­é—®é¢˜ï¼Œä»è€Œæ”»å…‹éš¾é¢˜ã€‚è¿™é¡¹æŠ€æœ¯æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨éœ€è¦å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä¾‹å¦‚ç®—æœ¯ã€å¸¸è¯†æ¨ç†å’Œç¬¦å·æ“ä½œç­‰ã€‚</mark>

<mark>CoT çš„ä¸€ä¸ªä¸»è¦ä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿå°†å›°éš¾çš„å•æ­¥é—®é¢˜è½¬åŒ–ä¸ºä¸€ç³»åˆ—ç®€å•æ­¥éª¤ï¼Œè¿›è€Œæé«˜ LLM æ¨ç†è¿‡ç¨‹çš„é€æ˜åº¦ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†å‡†ç¡®æ€§ï¼Œè¿˜ä¸ºæ¨¡å‹çš„å†³ç­–æä¾›äº†æœ‰ä»·å€¼çš„æ´å¯Ÿï¼Œæœ‰åŠ©äºè°ƒè¯•å’Œç†è§£ã€‚CoT å¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥å®ç°ï¼ŒåŒ…æ‹¬æä¾›å±•ç¤ºé€æ­¥æ¨ç†çš„å°‘æ ·æœ¬ç¤ºä¾‹ï¼Œæˆ–è€…ç›´æ¥æŒ‡ç¤ºæ¨¡å‹â€œé€æ­¥æ€è€ƒâ€ã€‚å…¶æœ‰æ•ˆæ€§æºäºå®ƒèƒ½å¤Ÿå¼•å¯¼æ¨¡å‹çš„å†…éƒ¨å¤„ç†æµç¨‹æœç€æ›´å®¡æ…ã€æ›´é€»è¾‘åŒ–çš„æ–¹å‘å‘å±•ã€‚å› æ­¤ï¼Œæ€ç»´é“¾å·²æˆä¸ºèµ‹èƒ½å½“ä»£ LLM é«˜çº§æ¨ç†èƒ½åŠ›çš„å…³é”®åŸºçŸ³ã€‚</mark>

<mark>è¿™ç§å¢å¼ºçš„é€æ˜åº¦ï¼Œä»¥åŠå°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¯ç®¡ç†å­é—®é¢˜çš„åšæ³•ï¼Œå¯¹äºè‡ªä¸»æ™ºèƒ½ä½“ï¼ˆAutonomous Agentsï¼‰å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºå®ƒä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ‰§è¡Œæ›´å¯é ã€æ›´å¯å®¡è®¡çš„è¡ŒåŠ¨ã€‚</mark>

<img width="800" height="564" alt="image" src="https://github.com/user-attachments/assets/3f0623d5-867b-41e0-9880-ff355a76aace" />

Fig. 1: CoT prompt alongside the detailed, step-by-step response generated by the agent.
<mark>å›¾ 1ï¼šæ€ç»´é“¾æç¤ºä»¥åŠæ™ºèƒ½ä½“ç”Ÿæˆçš„è¯¦ç»†ã€é€æ­¥å“åº”ã€‚</mark>

Let's see an example. It begins with a set of instructions that tell the AI how to think, defining its persona and a clear five-step process to follow. This is the prompt that initiates structured thinking.

<mark>è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ã€‚å®ƒé¦–å…ˆåŒ…å«ä¸€ç»„æŒ‡ä»¤ï¼Œå‘Šè¯‰ AI å¦‚ä½•æ€è€ƒï¼Œå®šä¹‰å…¶è§’è‰²ä»¥åŠä¸€ä¸ªæ˜ç¡®çš„äº”æ­¥æµç¨‹ã€‚è¿™æ˜¯å¯åŠ¨ç»“æ„åŒ–æ€è€ƒçš„æç¤ºã€‚</mark>

Following that, the example shows the CoT process in action. The section labeled "Agent's Thought Process" is the internal monologue where the model executes the instructed steps. This is the literal "chain of thought." Finally, the "Agent's Final Answer" is the polished, comprehensive output generated as a result of that careful, step-by-step reasoning process

<mark>éšåï¼Œè¯¥ç¤ºä¾‹å±•ç¤ºäº† CoT è¿‡ç¨‹çš„å®é™…åº”ç”¨ã€‚æ ‡è®°ä¸º"Agent's Thought Process"çš„éƒ¨åˆ†æ˜¯æ¨¡å‹æ‰§è¡ŒæŒ‡å®šæ­¥éª¤æ—¶çš„å†…å¿ƒç‹¬ç™½ï¼Œè¿™å°±æ˜¯å­—é¢æ„ä¹‰ä¸Šçš„"æ€ç»´é“¾"ã€‚æœ€åï¼Œ"Agent's Final Answer"æ˜¯ç»è¿‡ä»”ç»†ã€é€æ­¥æ¨ç†è¿‡ç¨‹åç”Ÿæˆçš„ç²¾ç‚¼ä¸”å…¨é¢çš„è¾“å‡ºã€‚</mark>

```python
You are an Information Retrieval Agent. Your goal is to answer the user's question comprehensively and accurately by thinking step-by-step.
Here's the process you must follow:

1. **Analyze the Query:** Understand the core subject and specific requirements of the user's question. Identify key entities, keywords, and the type of information being sought.
2. **Formulate Search Queries (for Knowledge Base):** Based on your analysis, generate a list of precise search queries that you would use to retrieve relevant information from a knowledge base or external tools.
3. **Simulate Information Retrieval (Self-Correction/Reasoning):**For each search query, mentally consider what kind of information you expect to find. If you were to retrieve the content, what would be the most relevant snippets? Think about potential ambiguities or
missing pieces.
4. **Synthesize Information:** Based on the simulated retrieval and your understanding of the user's original query, synthesize the gathered information into a coherent and complete answer. Ensure all aspects of the query are addressed.
5. **Review and Refine:** Before finalizing, critically evaluate your answer. Is it accurate? Is it comprehensive? Is it easy to understand? Is it concise? If not, identify what needs to be improved and how.

**User Query:** "Explain the main differences between classical computers and quantum computers, and briefly describe a potential application of quantum computing."

**Agent's Thought Process (Internal CoT Output - encouraged by the prompt):**

**Thought 1 (Analyze Query):**
The user wants two things:
1. Main differences between classical and quantum computers.
2. One potential application of quantum computing.
Keywords: classical computers, quantum computers, differences, potential application.

**Thought 2 (Formulate Search Queries):**
- "differences classical vs quantum computers"
- "how quantum computers work"
- "how classical computers work"
- "applications of quantum computing"

**Thought 3 (Simulate Information Retrieval & Identify Key Concepts):**
- From "differences": Expect concepts like bits vs. qubits, superposition, entanglement, probabilistic nature, computational power for specific problems.
- From "how they work": Classical uses transistors/binary. Quantum uses quantum mechanics.
- From "applications": Expect drug discovery, material science, cryptography, optimization.

**Thought 4 (Synthesize Information):**
Classical computers use bits (0 or 1), processing information sequentially. Quantum computers use qubits, which can be 0, 1, or both simultaneously (superposition), and can be entangled, allowing for vastly different computational approaches. This enables them to
solve certain problems (like factoring large numbers or simulating complex molecules) far more efficiently than classical computers. A potential application is in drug discovery, where quantum computers could simulate molecular interactions with unprecedented accuracy,
accelerating the development of new medicines.

**Thought 5 (Review and Refine):**
- Differences are covered (bits vs qubits, superposition, entanglement, processing).
- Application is given (drug discovery).
- Is it brief? Yes.
- Is it clear? Yes.
- Looks good.

**Agent's Final Answer (Output to User):**
Classical computers process information using bits, which can be either a 0 or a 1 at any given time, performing operations sequentially. In contrast, quantum computers utilize qubits, which can exist in multiple states simultaneously through superposition and can be linked through entanglement, allowing for exponentially more complex computations. This fundamental difference enables quantum machines to tackle certain problems, such as simulating molecular structures or breaking complex encryption, that are intractable for even the most powerful classical supercomputers. A significant potential application of quantum computing lies in drug discovery, where its ability to precisely model molecular behavior could revolutionize the development of new pharmaceuticals.

```

```python

ä½ æ˜¯ä¸€åä¿¡æ¯æ£€ç´¢æ™ºèƒ½ä½“ï¼ˆInformation Retrieval Agentï¼‰ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¾ªåºæ¸è¿›çš„æ€è€ƒï¼Œå…¨é¢ä¸”å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
ä½ å¿…é¡»éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

1. **åˆ†ææŸ¥è¯¢ï¼ˆAnalyze the Queryï¼‰ï¼š** ç†è§£ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒä¸»é¢˜å’Œå…·ä½“è¦æ±‚ã€‚è¯†åˆ«å…³é”®å®ä½“ã€å…³é”®è¯ä»¥åŠæ‰€éœ€ä¿¡æ¯çš„ç±»å‹ã€‚
2. **åˆ¶å®šæœç´¢æŸ¥è¯¢ï¼ˆFormulate Search Queries - é’ˆå¯¹çŸ¥è¯†åº“ï¼‰ï¼š** åŸºäºä½ çš„åˆ†æï¼Œç”Ÿæˆä¸€ä»½ç²¾ç¡®çš„æœç´¢æŸ¥è¯¢åˆ—è¡¨ï¼Œç”¨äºä»çŸ¥è¯†åº“æˆ–å¤–éƒ¨å·¥å…·ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚
3. **æ¨¡æ‹Ÿä¿¡æ¯æ£€ç´¢ï¼ˆSimulate Information Retrieval - è‡ªæˆ‘ä¿®æ­£/æ¨ç†ï¼‰ï¼š** å¯¹äºæ¯é¡¹æœç´¢æŸ¥è¯¢ï¼Œåœ¨è„‘æµ·ä¸­æ€è€ƒé¢„æœŸä¼šæ‰¾åˆ°å“ªç§ä¿¡æ¯ã€‚å¦‚æœæ£€ç´¢åˆ°å†…å®¹ï¼Œå“ªäº›ç‰‡æ®µä¼šæ˜¯æœ€ç›¸å…³çš„ï¼Ÿæ€è€ƒæ½œåœ¨çš„æ­§ä¹‰æˆ–ç¼ºå¤±çš„éƒ¨åˆ†ã€‚
4. **ç»¼åˆä¿¡æ¯ï¼ˆSynthesize Informationï¼‰ï¼š** åŸºäºæ¨¡æ‹Ÿæ£€ç´¢å’Œä½ å¯¹ç”¨æˆ·åŸå§‹æŸ¥è¯¢çš„ç†è§£ï¼Œå°†æ”¶é›†åˆ°çš„ä¿¡æ¯ç»¼åˆæˆä¸€ä¸ªè¿è´¯ä¸”å®Œæ•´çš„ç­”æ¡ˆã€‚ç¡®ä¿å›ç­”äº†æŸ¥è¯¢çš„æ‰€æœ‰æ–¹é¢ã€‚
5. **å®¡æŸ¥ä¸ä¼˜åŒ–ï¼ˆReview and Refineï¼‰ï¼š** åœ¨æœ€ç»ˆç¡®å®šç­”æ¡ˆå‰ï¼Œæ‰¹åˆ¤æ€§åœ°è¯„ä¼°ä½ çš„å›ç­”ã€‚å®ƒæ˜¯å¦å‡†ç¡®ï¼Ÿæ˜¯å¦å…¨é¢ï¼Ÿæ˜¯å¦æ˜“äºç†è§£ï¼Ÿæ˜¯å¦ç®€æ´ï¼Ÿå¦‚æœä¸æ˜¯ï¼Œç¡®å®šéœ€è¦æ”¹è¿›çš„å†…å®¹å’Œæ–¹å¼ã€‚

**ç”¨æˆ·æŸ¥è¯¢ï¼š**â€œè§£é‡Šç»å…¸è®¡ç®—æœºå’Œé‡å­è®¡ç®—æœºçš„ä¸»è¦åŒºåˆ«ï¼Œå¹¶ç®€è¦æè¿°ä¸€ä¸ªé‡å­è®¡ç®—çš„æ½œåœ¨åº”ç”¨ã€‚â€
**æ™ºèƒ½ä½“çš„æ€ç»´è¿‡ç¨‹ï¼ˆå†…éƒ¨æ€ç»´é“¾è¾“å‡º - ç”±æç¤ºé¼“åŠ±ç”Ÿæˆï¼‰**

**æ€è€ƒ 1ï¼ˆåˆ†ææŸ¥è¯¢ï¼‰ï¼š**
ç”¨æˆ·å¸Œæœ›å¾—åˆ°ä¸¤ç‚¹ä¿¡æ¯ï¼š
1. ç»å…¸è®¡ç®—æœºä¸é‡å­è®¡ç®—æœºçš„ä¸»è¦åŒºåˆ«ã€‚
2. ä¸€ä¸ªæ½œåœ¨çš„é‡å­è®¡ç®—åº”ç”¨ã€‚
å…³é”®è¯ï¼šç»å…¸è®¡ç®—æœºã€é‡å­è®¡ç®—æœºã€åŒºåˆ«ã€æ½œåœ¨åº”ç”¨ã€‚

æ€è€ƒ 2ï¼ˆåˆ¶å®šæœç´¢æŸ¥è¯¢ï¼‰ï¼š
- â€œç»å…¸è®¡ç®—æœº vs é‡å­è®¡ç®—æœº åŒºåˆ«â€
- â€œé‡å­è®¡ç®—æœºå¦‚ä½•å·¥ä½œâ€
- â€œç»å…¸è®¡ç®—æœºå¦‚ä½•å·¥ä½œâ€
- â€œé‡å­è®¡ç®—åº”ç”¨â€

**æ€è€ƒ 3ï¼ˆæ¨¡æ‹Ÿä¿¡æ¯æ£€ç´¢ä¸è¯†åˆ«å…³é”®æ¦‚å¿µï¼‰ï¼š**
- ä»â€œåŒºåˆ«â€ä¸­ï¼šé¢„æœŸä¼šæ‰¾åˆ°æ¯”ç‰¹ï¼ˆbitsï¼‰ vs é‡å­æ¯”ç‰¹ï¼ˆqubitsï¼‰ã€å åŠ æ€ï¼ˆsuperpositionï¼‰ã€çº ç¼ ï¼ˆentanglementï¼‰ã€æ¦‚ç‡æ€§è´¨ã€è§£å†³ç‰¹å®šé—®é¢˜çš„è®¡ç®—èƒ½åŠ›ç­‰æ¦‚å¿µã€‚
- ä»â€œå¦‚ä½•å·¥ä½œâ€ä¸­ï¼šç»å…¸è®¡ç®—æœºä½¿ç”¨æ™¶ä½“ç®¡/äºŒè¿›åˆ¶ã€‚é‡å­è®¡ç®—æœºä½¿ç”¨é‡å­åŠ›å­¦ã€‚
- ä»â€œåº”ç”¨â€ä¸­ï¼šé¢„æœŸä¼šæ‰¾åˆ°è¯ç‰©å‘ç°ã€ææ–™ç§‘å­¦ã€å¯†ç å­¦ã€ä¼˜åŒ–ç­‰ã€‚

**æ€è€ƒ 4ï¼ˆç»¼åˆä¿¡æ¯ï¼‰ï¼š**
ç»å…¸è®¡ç®—æœºä½¿ç”¨æ¯”ç‰¹ï¼ˆ0 æˆ– 1ï¼‰ï¼Œå¹¶æŒ‰é¡ºåºå¤„ç†ä¿¡æ¯ã€‚é‡å­è®¡ç®—æœºä½¿ç”¨é‡å­æ¯”ç‰¹ï¼Œé‡å­æ¯”ç‰¹å¯ä»¥åŒæ—¶å¤„äº 0ã€1 æˆ–ä¸¤è€…å…¼å…·çš„çŠ¶æ€ï¼ˆå åŠ æ€ï¼‰ï¼Œå¹¶ä¸”å¯ä»¥ç›¸äº’çº ç¼ ï¼Œä»è€Œå®ç°æˆªç„¶ä¸åŒçš„è®¡ç®—æ–¹æ³•ã€‚è¿™ä½¿å®ƒä»¬èƒ½å¤Ÿæ¯”ç»å…¸è®¡ç®—æœºæ›´é«˜æ•ˆåœ°è§£å†³æŸäº›ç‰¹å®šé—®é¢˜ï¼ˆå¦‚åˆ†è§£å¤§æ•°æˆ–æ¨¡æ‹Ÿå¤æ‚åˆ†å­ï¼‰ã€‚ä¸€ä¸ªæ½œåœ¨çš„åº”ç”¨æ˜¯è¯ç‰©å‘ç°ï¼Œé‡å­è®¡ç®—æœºå¯ä»¥å‰æ‰€æœªæœ‰åœ°å‡†ç¡®æ¨¡æ‹Ÿåˆ†å­ç›¸äº’ä½œç”¨ï¼Œä»è€ŒåŠ é€Ÿæ–°è¯çš„ç ”å‘ã€‚

**æ€è€ƒ 5ï¼ˆå®¡æŸ¥ä¸ä¼˜åŒ–ï¼‰ï¼š**
- åŒºåˆ«å·²æ¶µç›–ï¼ˆæ¯”ç‰¹ vs é‡å­æ¯”ç‰¹ã€å åŠ æ€ã€çº ç¼ ã€å¤„ç†æ–¹å¼ï¼‰ã€‚
- åº”ç”¨å·²ç»™å‡ºï¼ˆè¯ç‰©å‘ç°ï¼‰ã€‚
- æ˜¯å¦ç®€æ´ï¼Ÿæ˜¯ã€‚
- æ˜¯å¦æ¸…æ™°ï¼Ÿæ˜¯ã€‚
- çœ‹èµ·æ¥ä¸é”™ã€‚

**æ™ºèƒ½ä½“çš„æœ€ç»ˆç­”æ¡ˆï¼ˆè¾“å‡ºç»™ç”¨æˆ·ï¼‰ï¼š**
ç»å…¸è®¡ç®—æœºä½¿ç”¨æ¯”ç‰¹æ¥å¤„ç†ä¿¡æ¯ï¼Œæ¯”ç‰¹åœ¨ä»»ä¸€æ—¶åˆ»åªèƒ½æ˜¯ 0 æˆ– 1ï¼Œå¹¶æŒ‰é¡ºåºæ‰§è¡Œæ“ä½œã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œé‡å­è®¡ç®—æœºåˆ©ç”¨é‡å­æ¯”ç‰¹ï¼Œé‡å­æ¯”ç‰¹å¯ä»¥é€šè¿‡å åŠ æ€åŒæ—¶å­˜åœ¨äºå¤šç§çŠ¶æ€ï¼Œå¹¶é€šè¿‡çº ç¼ ç›¸äº’å…³è”ï¼Œä»è€Œå®ç°æŒ‡æ•°çº§å¤æ‚çš„è®¡ç®—ã€‚è¿™ç§æ ¹æœ¬æ€§çš„å·®å¼‚ä½¿å¾—é‡å­æœºå™¨èƒ½å¤Ÿè§£å†³æŸäº›é—®é¢˜ï¼ˆä¾‹å¦‚æ¨¡æ‹Ÿåˆ†å­ç»“æ„æˆ–ç ´è§£å¤æ‚åŠ å¯†ï¼‰ï¼Œè¿™äº›é—®é¢˜å¯¹äºæœ€å¼ºå¤§çš„ç»å…¸è¶…çº§è®¡ç®—æœºæ¥è¯´éƒ½æ˜¯æ— æ³•æ”»å…‹çš„ã€‚é‡å­è®¡ç®—çš„ä¸€ä¸ªé‡è¦çš„æ½œåœ¨åº”ç”¨åœ¨äºè¯ç‰©å‘ç°ï¼Œå®ƒç²¾ç¡®å»ºæ¨¡åˆ†å­è¡Œä¸ºçš„èƒ½åŠ›å¯ä»¥å½»åº•æ”¹å˜æ–°è¯çš„ç ”å‘ã€‚

```

**Tree-of-Thought (ToT)** is a reasoning technique that builds upon Chain-of-Thought(CoT). It allows large language models to explore multiple reasoning paths by branching into different intermediate steps, forming a tree structure (see Fig. 2) This approach supports complex problem-solving by enabling backtracking,self-correction, and exploration of alternative solutions. Maintaining a tree of possibilities allows the model to evaluate various reasoning trajectories before finalizing an answer. This iterative process enhances the model's ability to handle challenging tasks that require strategic planning and decision-making.
<mark>**æ€ç»´æ ‘ï¼ˆToTï¼‰** æ˜¯ä¸€ç§å»ºç«‹åœ¨æ€ç»´é“¾ï¼ˆChain-of-Thought, CoTï¼‰åŸºç¡€ä¸Šçš„æ¨ç†æŠ€å·§ã€‚å®ƒå…è®¸å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡åˆ†æ”¯åˆ°ä¸åŒçš„ä¸­é—´æ­¥éª¤ï¼Œæ¢ç´¢å¤šæ¡æ¨ç†è·¯å¾„ï¼Œä»è€Œå½¢æˆä¸€ä¸ªæ ‘çŠ¶ç»“æ„ï¼ˆå‚è§å›¾ 2ï¼‰ã€‚è¿™ç§æ–¹æ³•é€šè¿‡æ”¯æŒå›æº¯ã€è‡ªæˆ‘ä¿®æ­£å’Œæ¢ç´¢æ›¿ä»£è§£å†³æ–¹æ¡ˆï¼Œæ¥æ”¯æŒå¤æ‚çš„è§£é¢˜è¿‡ç¨‹ã€‚ç»´æŠ¤ä¸€æ£µå¯èƒ½æ€§ä¹‹æ ‘ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æœ€ç»ˆç¡®å®šç­”æ¡ˆä¹‹å‰è¯„ä¼°å„ç§æ¨ç†è½¨è¿¹ã€‚è¿™ç§è¿­ä»£è¿‡ç¨‹å¢å¼ºäº†æ¨¡å‹å¤„ç†éœ€è¦æˆ˜ç•¥è§„åˆ’å’Œå†³ç­–åˆ¶å®šçš„æŒ‘æˆ˜æ€§ä»»åŠ¡çš„èƒ½åŠ›ã€‚</mark>
<img width="2048" height="1445" alt="image" src="https://github.com/user-attachments/assets/c0bb1ace-e01e-4231-b730-7f166ec7478d" />
Fig.2: Example of Tree of Thoughts
å›¾ 2ï¼šæ€ç»´æ ‘ç¤ºä¾‹

**Self-correction**, also known as self-refinement, is a crucial aspect of an agent's reasoning process, particularly within Chain-of-Thought prompting. It involves the agent's internal evaluation of its generated content and intermediate thought processes. This critical review enables the agent to identify ambiguities, information gaps, or inaccuracies in its understanding or solutions. This iterative cycle of reviewing and refining allows the agent to adjust its approach, improve response quality, and ensure accuracy and thoroughness before delivering a final output. This internal critique enhances the agent's capacity to produce reliable and high-quality results, as demonstrated in examples within the dedicated Chapter 4.

<mark>**è‡ªæˆ‘ä¿®æ­£ï¼ˆSelf-correctionï¼‰**ï¼Œä¹Ÿç§°ä¸ºè‡ªæˆ‘ç²¾ç‚¼ï¼ˆself-refinementï¼‰ï¼Œæ˜¯æ™ºèƒ½ä½“æ¨ç†è¿‡ç¨‹çš„å…³é”®æ–¹é¢ï¼Œå°¤å…¶æ˜¯åœ¨æ€ç»´é“¾æç¤ºä¸­ã€‚å®ƒæ¶‰åŠæ™ºèƒ½ä½“å¯¹å…¶ç”Ÿæˆçš„å†…å®¹å’Œä¸­é—´æ€ç»´è¿‡ç¨‹è¿›è¡Œå†…éƒ¨è¯„ä¼°ã€‚è¿™ç§æ‰¹åˆ¤æ€§å®¡æŸ¥ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè¯†åˆ«å…¶ç†è§£æˆ–è§£å†³æ–¹æ¡ˆä¸­çš„æ­§ä¹‰ã€ä¿¡æ¯ç©ºç™½æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚è¿™ç§å®¡æŸ¥å’Œç²¾ç‚¼çš„è¿­ä»£å¾ªç¯å…è®¸æ™ºèƒ½ä½“è°ƒæ•´å…¶æ–¹æ³•ã€æé«˜å“åº”è´¨é‡ï¼Œå¹¶ç¡®ä¿åœ¨äº¤ä»˜æœ€ç»ˆè¾“å‡ºå‰çš„å‡†ç¡®æ€§å’Œå½»åº•æ€§ã€‚è¿™ç§å†…éƒ¨æ‰¹åˆ¤å¢å¼ºäº†æ™ºèƒ½ä½“ç”Ÿæˆå¯é å’Œé«˜è´¨é‡ç»“æœçš„èƒ½åŠ›ï¼Œæ­£å¦‚ä¸“é—¨çš„ç¬¬ 4 ç« ç¤ºä¾‹æ‰€ç¤ºã€‚</mark>


This example demonstrates a systematic process of self-correction, crucial for refining AI-generated content. It involves an iterative loop of drafting, reviewing against original requirements, and implementing specific improvements. The illustration begins by outlining the AI's function as a "Self-Correction Agent" with a67defined five-step analytical and revision workflow. Following this, a subpar "InitialDraft" of a social media post is presented. The "Self-Correction Agent's Thought Process" forms the core of the demonstration. Here, the Agent critically evaluates the draft according to its instructions, pinpointing weaknesses such as low engagement and a vague call to action. It then suggests concrete enhancements, including the use of more impactful verbs and emojis. The process concludes with the "Final Revised Content," a polished and notably improved version that integrates the self-identified adjustments.

<mark>è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„è‡ªæˆ‘ä¿®æ­£è¿‡ç¨‹ï¼Œè¿™å¯¹äºç²¾ç‚¼ AI ç”Ÿæˆçš„å†…å®¹è‡³å…³é‡è¦ã€‚å®ƒæ¶‰åŠä¸€ä¸ªèµ·è‰ã€å¯¹ç…§åŸå§‹è¦æ±‚è¿›è¡Œå®¡æŸ¥ï¼Œä»¥åŠå®æ–½å…·ä½“æ”¹è¿›çš„è¿­ä»£å¾ªç¯ã€‚è¯¥ç¤ºä¾‹é¦–å…ˆæ¦‚è¿°äº† AI ä½œä¸ºâ€œè‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“â€ï¼ˆSelf-Correction Agentï¼‰çš„åŠŸèƒ½ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªæ˜ç¡®çš„äº”æ­¥åˆ†æå’Œä¿®è®¢å·¥ä½œæµã€‚éšåï¼Œå‘ˆç°äº†ä¸€ä»½è´¨é‡æ¬ ä½³çš„ç¤¾äº¤åª’ä½“å¸–å­â€œåˆå§‹è‰ç¨¿â€ï¼ˆInitial Draftï¼‰ã€‚â€œè‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“çš„æ€ç»´è¿‡ç¨‹â€ï¼ˆSelf-Correction Agent's Thought Processï¼‰æ„æˆäº†æ¼”ç¤ºçš„æ ¸å¿ƒã€‚åœ¨è¿™ä¸ªç¯èŠ‚ï¼Œæ™ºèƒ½ä½“æ ¹æ®æŒ‡ä»¤æ‰¹åˆ¤æ€§åœ°è¯„ä¼°è‰ç¨¿ï¼ŒæŒ‡å‡ºäº†è¯¸å¦‚å‚ä¸åº¦ä½å’Œè¡ŒåŠ¨å·å¬æ¨¡ç³Šç­‰å¼±ç‚¹ã€‚ç„¶åï¼Œå®ƒæå‡ºäº†å…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ŒåŒ…æ‹¬ä½¿ç”¨æ›´å…·å½±å“åŠ›çš„åŠ¨è¯å’Œè¡¨æƒ…ç¬¦å·ã€‚æ•´ä¸ªè¿‡ç¨‹æœ€ç»ˆä»¥â€œæœ€ç»ˆä¿®è®¢å†…å®¹â€ï¼ˆFinal Revised Contentï¼‰æ”¶å°¾ï¼Œè¿™æ˜¯ä¸€ä¸ªæ•´åˆäº†è‡ªæˆ‘è¯†åˆ«è°ƒæ•´åçš„ã€æ›´ç²¾ç‚¼ä¸”æ˜¾è‘—æ”¹å–„çš„ç‰ˆæœ¬ã€‚</mark>

```python
You are a highly critical and detail-oriented Self-Correction Agent.
Your task is to review a previously generated piece of content against its original requirements and identify areas for improvement.
Your goal is to refine the content to be more accurate, comprehensive, engaging, and aligned with the prompt.

Here's the process you must follow for self-correction:

1. **Understand Original Requirements:** Review the initial prompt/requirements that led to the content's creation. What was the *original intent*? What were the key constraints or goals?
2. **Analyze Current Content:** Read the provided content carefully.
3. **Identify Discrepancies/Weaknesses:** Compare the current content against the original requirements. Look for:
* **Accuracy Issues:** Are there any factual errors or misleading statements?
* **Completeness Gaps:** Does it fully address all aspects of the original prompt? Is anything missing?
* **Clarity & Coherence:** Is the language clear, concise, and easy to understand? Does it flow logically?
* **Tone & Style:** Does it match the desired tone and style (e.g., professional, engaging, concise)?
* **Engagement:** Is it captivating? Does it hold the reader's attention?
* **Redundancy/Verbosity:** Can any parts be condensed or removed without losing meaning?
4. **Propose Specific Improvements:** For each identified weakness, suggest concrete and actionable changes. Do not just state the problem; propose a solution.
5. **Generate Revised Content:** Based on your proposed improvements, rewrite the original content to incorporate all the necessary changes. Ensure the revised content is polished and ready for final use.

**Original Prompt/Requirements:** "Write a short, engaging social media post (max 150 characters) announcing a new eco-friendly product line: 'GreenTech Gadgets'."

**Initial Draft (Content to be corrected):**

"We have new products. They are green and techy. Buy GreenTech Gadgets now!"

**Self-Correction Agent's Thought Process (Internal CoT Output - encouraged by the prompt):**

**Thought 1 (Understand Original Requirements):**
- Short, engaging social media post.
- Max 150 characters.
- Announce "GreenTech Gadgets" - a new eco-friendly product line.

**Thought 2 (Analyze Current Content):**
"We have new products. They are green and techy. Buy GreenTech Gadgets now!" (64 characters)

**Thought 3 (Identify Discrepancies/Weaknesses):**
- **Engaging:** Not very engaging. Sounds generic.
- **Eco-friendly:** Implied by "green," but not explicitly highlighted as a benefit.
- **Call to Action:** "Buy now!" is okay, but could be more compelling.
- **Conciseness:** It's short, but could use stronger verbs/phrasing.
- **Impact:** Lacks excitement for a new product launch.

**Thought 4 (Propose Specific Improvements):**
- Make it more dynamic and exciting.
- Emphasize "eco-friendly" and "innovation."
- Use stronger verbs and more active voice.
- Add a clear, engaging call to action.
- Ensure it stays under 150 characters.

**Thought 5 (Generate Revised Content):**
Original: "We have new products. They are green and techy. Buy GreenTech Gadgets now!"
Revised idea 1: "ğŸŒ± Discover GreenTech Gadgets! Our new eco-friendly line blends innovation with sustainability. Go green, go smart! Shop now! #EcoFriendly #GreenTech" (148 characters)
This revision directly addresses eco-friendliness, uses emojis for engagement, adds a stronger call to action, and includes relevant hashtags while staying within the character limit.

**Self-Correction Agent's Final Revised Content (Output to User):**

ğŸŒ± Discover GreenTech Gadgets! Our new eco-friendly line blends innovation with sustainability. Go green, go smart! Shop now! #EcoFriendly #GreenTech

```

```python

è‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“ï¼ˆSelf-Correction Agentï¼‰å·¥ä½œæµç¨‹ç¤ºä¾‹
ä½ æ˜¯ä¸€åé«˜åº¦æ‰¹åˆ¤æ€§ä¸”æ³¨é‡ç»†èŠ‚çš„è‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“ï¼ˆSelf-Correction Agentï¼‰ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®åŸå§‹è¦æ±‚å®¡æŸ¥ä¸€æ®µå…ˆå‰ç”Ÿæˆçš„å†…å®¹ï¼Œå¹¶è¯†åˆ«å‡ºéœ€è¦æ”¹è¿›çš„åŒºåŸŸã€‚ä½ çš„ç›®æ ‡æ˜¯ç²¾ç‚¼å†…å®¹ï¼Œä½¿å…¶æ›´å‡†ç¡®ã€æ›´å…¨é¢ã€æ›´å…·å¸å¼•åŠ›ï¼Œå¹¶ä¸æç¤ºï¼ˆPromptï¼‰ä¿æŒä¸€è‡´ã€‚

ä½ å¿…é¡»éµå¾ªä»¥ä¸‹è‡ªæˆ‘ä¿®æ­£æµç¨‹ï¼š

1. **ç†è§£åŸå§‹è¦æ±‚ï¼ˆUnderstand Original Requirementsï¼‰ï¼š **å®¡æŸ¥ç”Ÿæˆè¯¥å†…å®¹çš„åˆå§‹æç¤º/è¦æ±‚ã€‚åŸå§‹æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿå…³é”®çš„çº¦æŸæˆ–ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ
2. **åˆ†æç°æœ‰å†…å®¹ï¼ˆAnalyze Current Contentï¼‰ï¼š** ä»”ç»†é˜…è¯»æä¾›çš„å†…å®¹ã€‚
3. **è¯†åˆ«å·®å¼‚/å¼±ç‚¹ï¼ˆIdentify Discrepancies/Weaknessesï¼‰ï¼š** å°†ç°æœ‰å†…å®¹ä¸åŸå§‹è¦æ±‚è¿›è¡Œæ¯”è¾ƒã€‚æŸ¥æ‰¾ä»¥ä¸‹é—®é¢˜ï¼š
* **å‡†ç¡®æ€§é—®é¢˜ï¼š** æ˜¯å¦å­˜åœ¨ä»»ä½•äº‹å®é”™è¯¯æˆ–è¯¯å¯¼æ€§é™ˆè¿°ï¼Ÿ
* **å®Œæ•´æ€§ç¼ºå¤±ï¼š** æ˜¯å¦å……åˆ†è§£å†³äº†åŸå§‹æç¤ºçš„æ‰€æœ‰æ–¹é¢ï¼Ÿæ˜¯å¦é—æ¼äº†ä»»ä½•å†…å®¹ï¼Ÿ
* **æ¸…æ™°åº¦ä¸è¿è´¯æ€§ï¼š** è¯­è¨€æ˜¯å¦æ¸…æ™°ã€ç®€æ´ã€æ˜“äºç†è§£ï¼Ÿé€»è¾‘æµç¨‹æ˜¯å¦é¡ºç•…ï¼Ÿ
* **è¯­æ°”ä¸é£æ ¼ï¼š** æ˜¯å¦ä¸æ‰€éœ€çš„è¯­æ°”å’Œé£æ ¼ï¼ˆä¾‹å¦‚ï¼Œä¸“ä¸šã€å¼•äººå…¥èƒœã€ç®€æ´ï¼‰åŒ¹é…ï¼Ÿ
* **å‚ä¸åº¦ï¼š** æ˜¯å¦å¼•äººæ³¨ç›®ï¼Ÿèƒ½å¦å¸å¼•è¯»è€…çš„æ³¨æ„åŠ›ï¼Ÿ
* **å†—ä½™/å•°å—¦ï¼š** æ˜¯å¦å¯ä»¥åœ¨ä¸å¤±åŸæ„çš„æƒ…å†µä¸‹ï¼Œå¯¹æŸäº›éƒ¨åˆ†è¿›è¡Œç²¾ç®€æˆ–åˆ é™¤ï¼Ÿ
4. **æå‡ºå…·ä½“æ”¹è¿›å»ºè®®ï¼ˆPropose Specific Improvementsï¼‰ï¼š** å¯¹äºè¯†åˆ«å‡ºçš„æ¯ä¸ªå¼±ç‚¹ï¼Œæå‡ºå…·ä½“ä¸”å¯æ“ä½œçš„æ›´æ”¹ã€‚ä¸è¦åªé™ˆè¿°é—®é¢˜ï¼Œè¿˜è¦æå‡ºè§£å†³æ–¹æ¡ˆã€‚
5. **ç”Ÿæˆä¿®è®¢å†…å®¹ï¼ˆGenerate Revised Contentï¼‰ï¼š** åŸºäºä½ æå‡ºçš„æ”¹è¿›å»ºè®®ï¼Œé‡å†™åŸå§‹å†…å®¹ä»¥çº³å…¥æ‰€æœ‰å¿…è¦çš„æ›´æ”¹ã€‚ç¡®ä¿ä¿®è®¢åçš„å†…å®¹ç»è¿‡æ¶¦é¥°ï¼Œå¯ä¾›æœ€ç»ˆä½¿ç”¨ã€‚

åŸå§‹æç¤º/è¦æ±‚ï¼š â€œæ’°å†™ä¸€ç¯‡ç®€çŸ­ã€å¼•äººå…¥èƒœçš„ç¤¾äº¤åª’ä½“å¸–å­ï¼ˆæœ€å¤š 150 ä¸ªå­—ç¬¦ï¼‰ï¼Œå®£å¸ƒæ–°çš„ç¯ä¿äº§å“çº¿ï¼šâ€˜GreenTech Gadgetsâ€™ã€‚â€

**ï¼ˆåˆå§‹è‰ç¨¿ - å¾…ä¿®æ­£çš„å†…å®¹ï¼‰ï¼š**

â€œæˆ‘ä»¬æœ‰æ–°äº§å“ã€‚å®ƒä»¬æ˜¯ç»¿è‰²çš„ï¼Œç§‘æŠ€æ„Ÿåè¶³ã€‚ç°åœ¨å°±è´­ä¹° GreenTech Gadgets å§ï¼â€

**è‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“çš„æ€ç»´è¿‡ç¨‹ï¼ˆå†…éƒ¨æ€ç»´é“¾è¾“å‡º - ç”±æç¤ºé¼“åŠ±ç”Ÿæˆï¼‰ï¼š**

**æ€è€ƒ 1ï¼ˆç†è§£åŸå§‹è¦æ±‚ï¼‰ï¼š**
ç®€çŸ­ã€å¼•äººå…¥èƒœçš„ç¤¾äº¤åª’ä½“å¸–å­ã€‚
æœ€å¤š 150 ä¸ªå­—ç¬¦ã€‚
å®£å¸ƒâ€œGreenTech Gadgetsâ€â€”â€”ä¸€æ¡æ–°çš„ç¯ä¿äº§å“çº¿ã€‚

**æ€è€ƒ 2ï¼ˆåˆ†æç°æœ‰å†…å®¹ï¼‰ï¼š**
â€œæˆ‘ä»¬æœ‰æ–°äº§å“ã€‚å®ƒä»¬æ˜¯ç»¿è‰²çš„ï¼Œç§‘æŠ€æ„Ÿåè¶³ã€‚ç°åœ¨å°±è´­ä¹° GreenTech Gadgets å§ï¼â€ï¼ˆ64 ä¸ªå­—ç¬¦ï¼‰

**æ€è€ƒ 3ï¼ˆè¯†åˆ«å·®å¼‚/å¼±ç‚¹ï¼‰ï¼š**
å‚ä¸åº¦ï¼š ä¸å¤Ÿå¸å¼•äººã€‚å¬èµ·æ¥å¾ˆæ™®é€šã€‚
ç¯ä¿æ€§ï¼š ç”±â€œç»¿è‰²â€ï¼ˆgreenï¼‰æš—ç¤ºï¼Œä½†æ²¡æœ‰æ˜ç¡®å¼ºè°ƒå…¶ç›Šå¤„ã€‚
è¡ŒåŠ¨å·å¬ï¼š â€œç°åœ¨å°±è´­ä¹°ï¼â€å°šå¯ï¼Œä½†å¯ä»¥æ›´æœ‰è¯´æœåŠ›ã€‚
ç®€æ´æ€§ï¼š è™½ç„¶çŸ­ï¼Œä½†å¯ä»¥ä½¿ç”¨æ›´å¼ºæœ‰åŠ›çš„åŠ¨è¯/æªè¾ã€‚
å½±å“åŠ›ï¼š ç¼ºä¹æ–°äº§å“å‘å¸ƒåº”æœ‰çš„å…´å¥‹æ„Ÿã€‚

**æ€è€ƒ 4ï¼ˆæå‡ºå…·ä½“æ”¹è¿›å»ºè®®ï¼‰ï¼š**
ä½¿å…¶æ›´å…·æ´»åŠ›å’Œå…´å¥‹æ„Ÿã€‚
å¼ºè°ƒ**â€œç¯ä¿â€å’Œâ€œåˆ›æ–°â€**ã€‚
ä½¿ç”¨æ›´å¼ºæœ‰åŠ›çš„åŠ¨è¯å’Œæ›´ä¸»åŠ¨çš„è¯­æ€ã€‚
æ·»åŠ ä¸€ä¸ªæ¸…æ™°ã€å¼•äººå…¥èƒœçš„è¡ŒåŠ¨å·å¬ã€‚
ç¡®ä¿å­—ç¬¦æ•°ä¿æŒåœ¨ 150 ä»¥å†…ã€‚

**æ€è€ƒ 5ï¼ˆç”Ÿæˆä¿®è®¢å†…å®¹ï¼‰ï¼š**
åŸç¨¿ï¼šâ€œæˆ‘ä»¬æœ‰æ–°äº§å“ã€‚å®ƒä»¬æ˜¯ç»¿è‰²çš„ï¼Œç§‘æŠ€æ„Ÿåè¶³ã€‚ç°åœ¨å°±è´­ä¹° GreenTech Gadgets å§ï¼â€
ä¿®è®¢æ€è·¯ 1ï¼šâ€œğŸŒ± æ¢ç´¢ GreenTech Gadgetsï¼ æˆ‘ä»¬çš„æ–°ç¯ä¿ç³»åˆ—èåˆäº†åˆ›æ–°ä¸å¯æŒç»­æ€§ã€‚é€‰æ‹©ç»¿è‰²ï¼Œé€‰æ‹©æ™ºæ…§ï¼ç«‹å³è´­ä¹°ï¼ #EcoFriendly #GreenTechâ€ï¼ˆ148 ä¸ªå­—ç¬¦ï¼‰
è¿™æ¬¡ä¿®è®¢ç›´æ¥å¼ºè°ƒäº†ç¯ä¿æ€§ï¼Œä½¿ç”¨äº†è¡¨æƒ…ç¬¦å·æ¥å¢åŠ å‚ä¸åº¦ï¼Œæ·»åŠ äº†æ›´å¼ºæœ‰åŠ›çš„è¡ŒåŠ¨å·å¬ï¼Œå¹¶åŒ…å«äº†ç›¸å…³æ ‡ç­¾ï¼ŒåŒæ—¶ä¿æŒåœ¨å­—ç¬¦é™åˆ¶å†…ã€‚

**è‡ªæˆ‘ä¿®æ­£æ™ºèƒ½ä½“çš„æœ€ç»ˆä¿®è®¢å†…å®¹ï¼ˆè¾“å‡ºç»™ç”¨æˆ·ï¼‰ï¼š**
ğŸŒ± æ¢ç´¢ GreenTech Gadgetsï¼ æˆ‘ä»¬çš„æ–°ç¯ä¿ç³»åˆ—èåˆäº†åˆ›æ–°ä¸å¯æŒç»­æ€§ã€‚é€‰æ‹©ç»¿è‰²ï¼Œé€‰æ‹©æ™ºæ…§ï¼ç«‹å³è´­ä¹°ï¼ #EcoFriendly #GreenTech
```

Fundamentally, this technique integrates a quality control measure directly into the Agent's content generation, yielding more refined, precise, and superior results that more effectively meet intricate user demands.

<mark>ä»æ ¹æœ¬ä¸Šè¯´ï¼Œè¿™é¡¹æŠ€å·§å°†è´¨é‡æ§åˆ¶æªæ–½ç›´æ¥æ•´åˆåˆ°æ™ºèƒ½ä½“ï¼ˆAgentï¼‰çš„å†…å®¹ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œäº§ç”Ÿæ›´ç²¾ç‚¼ã€æ›´ç²¾ç¡®ã€æ›´ä¼˜è´¨çš„ç»“æœï¼Œèƒ½æ›´æœ‰æ•ˆåœ°æ»¡è¶³å¤æ‚çš„ç”¨æˆ·éœ€æ±‚ã€‚</mark>

**Program-Aided Language Models (PALMs)** integrate LLMs with symbolic reasoning capabilities. This integration allows the LLM to generate and execute code, such as Python, as part of its problem-solving process. PALMs offload complex calculations, logical operations, and data manipulation to a deterministic programming environment. This approach utilizes the strengths of traditional programming for tasks where LLMs might exhibit limitations in accuracy or consistency. When faced with symbolic challenges, the model can produce code, execute it, and convert the results into natural language. This hybrid methodology combines the LLM's understanding and generation abilities with precise computation, enabling the model to address a wider range of complex problems with potentially increased reliability and accuracy. This is important for agents as it allows them to perform more accurate and reliable actions by leveraging precise computation alongside their understanding and generation capabilities. An example is the use of external tools within Google's ADK for generating code.

<mark>**ç¨‹åºè¾…åŠ©è¯­è¨€æ¨¡å‹ï¼ˆProgram-Aided Language Models, PALMsï¼‰** å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ç¬¦å·æ¨ç†èƒ½åŠ›ç›¸ç»“åˆã€‚è¿™ç§é›†æˆå…è®¸ LLM åœ¨é—®é¢˜è§£å†³è¿‡ç¨‹ä¸­ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ï¼Œä¾‹å¦‚ Pythonã€‚PALMs å°†å¤æ‚çš„è®¡ç®—ã€é€»è¾‘æ“ä½œå’Œæ•°æ®å¤„ç†å·¥ä½œè½¬ç§»åˆ°ä¸€ä¸ªç¡®å®šçš„ç¼–ç¨‹ç¯å¢ƒä¸­ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†ä¼ ç»Ÿç¼–ç¨‹çš„ä¼˜åŠ¿ï¼Œæ¥å¤„ç† LLM åœ¨å‡†ç¡®æ€§æˆ–ä¸€è‡´æ€§æ–¹é¢å¯èƒ½è¡¨ç°å‡ºå±€é™æ€§çš„ä»»åŠ¡ã€‚å½“é¢ä¸´ç¬¦å·æŒ‘æˆ˜æ—¶ï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆä»£ç ã€æ‰§è¡Œä»£ç ï¼Œå¹¶å°†ç»“æœè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ã€‚è¿™ç§æ··åˆæ–¹æ³•å°† LLM çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ä¸ç²¾ç¡®è®¡ç®—ç›¸ç»“åˆï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè§£å†³æ›´å¹¿æ³›çš„å¤æ‚é—®é¢˜ï¼Œå¹¶æœ‰å¯èƒ½æé«˜å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™å¯¹æ™ºèƒ½ä½“æ¥è¯´è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒå…è®¸æ™ºèƒ½ä½“é€šè¿‡åˆ©ç”¨ç²¾ç¡®è®¡ç®—ä»¥åŠè‡ªèº«çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œæ‰§è¡Œæ›´å‡†ç¡®ã€æ›´å¯é çš„è¡ŒåŠ¨ã€‚ä¸€ä¸ªä¾‹å­æ˜¯ Google ADK ä¸­ä½¿ç”¨å¤–éƒ¨å·¥å…·æ¥ç”Ÿæˆä»£ç ã€‚</mark>

```python
from google.adk.tools import agent_tool
from google.adk.agents import Agent
from google.adk.tools import google_search
from google.adk.code_executors import BuiltInCodeExecutor
search_agent = Agent(
   model='gemini-2.0-flash',
   name='SearchAgent',
   instruction="""
   You're a specialist in Google Search
   """,
   tools=[google_search],
)
coding_agent = Agent(
   model='gemini-2.0-flash',
   name='CodeAgent',
   instruction="""
   You're a specialist in Code Execution
9
10
""",
   code_executor=[BuiltInCodeExecutor],
)
root_agent = Agent(
   name="RootAgent",
   model="gemini-2.0-flash",
   description="Root Agent",
   tools=[agent_tool.AgentTool(agent=search_agent),
agent_tool.AgentTool(agent=coding_agent)],
)
```

**Reinforcement Learning with Verifiable Rewards (RLVR):** While effective, the standard Chain-of-Thought (CoT) prompting used by many LLMs is a somewhat basic approach to reasoning. It generates a single, predetermined line of thought without adapting to the complexity of the problem. To overcome these limitations, a new class of specialized "reasoning models" has been developed. These models operate differently by dedicating a variable amount of "thinking" time before providing an answer. This "thinking" process produces a more extensive and dynamic Chain-of-Thought that can be thousands of tokens long. This extended reasoning allows for more complex behaviors like self-correction and backtracking, with the model dedicating more effort to harder problems. The key innovation enabling these models is a training strategy called Reinforcement Learning from Verifiable Rewards (RLVR). By training the model on problems with known correct answers (like math or code), it learns through trial and error to generate effective, long-form reasoning. This allows the model to evolve its problem-solving abilities without direct human supervision. Ultimately, these reasoning models don't just produce an answer; they generate a "reasoning trajectory" that demonstrates advanced skills like planning, monitoring, and evaluation. This enhanced ability to reason and strategize is fundamental to the development of autonomous AI agents, which can break down and solve complex tasks with minimal human intervention.

<mark>**å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning with Verifiable Rewards, RLVRï¼‰ï¼š** å°½ç®¡æœ‰æ•ˆï¼Œä½†è®¸å¤š LLM ä½¿ç”¨çš„æ ‡å‡†æ€ç»´é“¾ï¼ˆChain-of-Thought, CoTï¼‰æç¤ºæ˜¯ä¸€ç§ç›¸å¯¹åŸºç¡€çš„æ¨ç†æ–¹æ³•ã€‚å®ƒä¼šç”Ÿæˆä¸€æ¡å•ä¸€ã€é¢„å®šçš„æ€ç»´è·¯çº¿ï¼Œè€Œæ— æ³•é€‚åº”é—®é¢˜çš„å¤æ‚æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œä¸€ç±»æ–°å‹çš„ä¸“ä¸š**ã€Œæ¨ç†æ¨¡å‹ã€å·²è¢«å¼€å‘å‡ºæ¥ã€‚è¿™äº›æ¨¡å‹çš„è¿ä½œæ–¹å¼æœ‰æ‰€ä¸åŒï¼Œå®ƒä»¬ä¼šåœ¨æä¾›ç­”æ¡ˆä¹‹å‰æŠ•å…¥å¯å˜æ—¶é•¿çš„ã€Œæ€è€ƒã€æ—¶é—´ã€‚è¿™ä¸ªã€Œæ€è€ƒã€è¿‡ç¨‹ä¼šäº§ç”Ÿæ›´å¹¿æ³›ã€æ›´å…·åŠ¨æ€æ€§çš„æ€ç»´é“¾**ï¼Œé•¿åº¦å¯è¾¾æ•°åƒä¸ª Tokenã€‚è¿™ç§æ‰©å±•çš„æ¨ç†èƒ½å¤Ÿæ”¯æŒæ›´å¤æ‚çš„è¡Œä¸ºï¼Œä¾‹å¦‚è‡ªæˆ‘ä¿®æ­£å’Œå›æº¯ï¼Œæ¨¡å‹ä¼šé’ˆå¯¹éš¾åº¦æ›´é«˜çš„é—®é¢˜æŠ•å…¥æ›´å¤šç²¾åŠ›ã€‚èµ‹èƒ½è¿™äº›æ¨¡å‹çš„å…³é”®åˆ›æ–°æ˜¯ä¸€ç§åä¸ºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰çš„è®­ç»ƒç­–ç•¥ã€‚é€šè¿‡åœ¨å·²çŸ¥æ­£ç¡®ç­”æ¡ˆçš„é—®é¢˜ä¸Šï¼ˆä¾‹å¦‚æ•°å­¦æˆ–ä»£ç ï¼‰å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œæ¨¡å‹é€šè¿‡è¯•é”™å­¦ä¹ ç”Ÿæˆæœ‰æ•ˆçš„é•¿ç¯‡æ¨ç†ã€‚è¿™ä½¿å¾—æ¨¡å‹æ— éœ€ç›´æ¥çš„äººç±»ç›‘ç£å³å¯æ¼”åŒ–å…¶é—®é¢˜è§£å†³èƒ½åŠ›ã€‚æœ€ç»ˆï¼Œè¿™äº›æ¨ç†æ¨¡å‹ä¸ä»…ä¼šäº§ç”Ÿç­”æ¡ˆï¼Œè¿˜ä¼šç”Ÿæˆä¸€æ¡ã€Œæ¨ç†è½¨è¿¹ã€ï¼Œå±•ç¤ºå‡ºè§„åˆ’ã€ç›‘æ§å’Œè¯„ä¼°ç­‰é«˜çº§æŠ€èƒ½ã€‚è¿™ç§å¢å¼ºçš„æ¨ç†å’Œç­–ç•¥åˆ¶å®šèƒ½åŠ›ï¼Œæ˜¯è‡ªä¸» AI æ™ºèƒ½ä½“å‘å±•çš„åŸºçŸ³ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿä»¥æœ€å°‘çš„äººå·¥å¹²é¢„æ¥æ‹†è§£å’Œè§£å†³å¤æ‚çš„ä»»åŠ¡ã€‚</mark>

**ReAct** (Reasoning and Acting, see Fig. 3, where KB stands for Knowledge Base) is a paradigm that integrates Chain-of-Thought (CoT) prompting with an agent's ability to interact with external environments through tools. Unlike generative models that produce a final answer, a ReAct agent reasons about which actions to take. This reasoning phase involves an internal planning process, similar to CoT, where the agent determines its next steps, considers available tools, and anticipates outcomes. Following this, the agent acts by executing a tool or function call, such as querying a database, performing a calculation, or interacting with an API.

<mark>**ReAct**ï¼ˆæ¨ç†ä¸è¡ŒåŠ¨ï¼Œå‚è§å›¾ 3ï¼Œå…¶ä¸­ KB ä»£è¡¨çŸ¥è¯†åº“ï¼‰æ˜¯ä¸€ç§å°†æ€ç»´é“¾ï¼ˆCoTï¼‰æç¤ºä¸æ™ºèƒ½ä½“é€šè¿‡å·¥å…·ä¸å¤–éƒ¨ç¯å¢ƒè¿›è¡Œäº¤äº’èƒ½åŠ›ç›¸ç»“åˆçš„èŒƒå¼ã€‚ä¸ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆçš„ç”Ÿæˆæ¨¡å‹ä¸åŒï¼ŒReAct æ™ºèƒ½ä½“ä¼šæ¨ç†è¦é‡‡å–å“ªäº›è¡ŒåŠ¨ã€‚è¿™ä¸ªæ¨ç†é˜¶æ®µæ¶‰åŠä¸€ä¸ªç±»ä¼¼äº CoT çš„å†…éƒ¨è§„åˆ’è¿‡ç¨‹ï¼Œæ™ºèƒ½ä½“åœ¨å…¶ä¸­ç¡®å®šå…¶åç»­æ­¥éª¤ã€è€ƒè™‘å¯ç”¨çš„å·¥å…·å¹¶é¢„æµ‹ç»“æœã€‚éšåï¼Œæ™ºèƒ½ä½“é€šè¿‡æ‰§è¡Œå·¥å…·æˆ–å‡½æ•°è°ƒç”¨ï¼ˆä¾‹å¦‚æŸ¥è¯¢æ•°æ®åº“ã€æ‰§è¡Œè®¡ç®—æˆ–ä¸ API äº¤äº’ï¼‰æ¥é‡‡å–è¡ŒåŠ¨ã€‚</mark>

<img width="2048" height="1445" alt="image" src="https://github.com/user-attachments/assets/6ddc2354-f418-4271-a920-792a5bd0ff05" />

Fig.3: Reasoning and Act
<mark>å›¾ 3ï¼šæ¨ç†ä¸è¡ŒåŠ¨</mark>

ReAct operates in an interleaved manner: the agent executes an action, observes the outcome, and incorporates this observation into subsequent reasoning. This iterative loop of â€œThought, Action, Observation, Thought...â€ allows the agent to dynamically adapt its plan, correct errors, and achieve goals requiring multiple interactions with the environment. This provides a more robust and flexible problem-solving approach compared to linear CoT, as the agent responds to real-time feedback. By combining language model understanding and generation with the capability to use tools, ReAct enables agents to perform complex tasks requiring both reasoning and practical execution. This approach is crucial for agents as it allows them to not only reason but also to practically execute steps and interact with dynamic environments.

<mark>ReAct ä»¥äº¤é”™çš„æ–¹å¼è¿ä½œï¼šæ™ºèƒ½ä½“æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œï¼Œè§‚å¯Ÿç»“æœï¼Œå¹¶å°†æ­¤è§‚å¯Ÿç»“æœçº³å…¥éšåçš„æ¨ç†ä¸­ã€‚è¿™ç§ã€Œæ€è€ƒã€è¡ŒåŠ¨ã€è§‚å¯Ÿã€æ€è€ƒâ€¦â€¦ã€çš„è¿­ä»£å¾ªç¯å…è®¸æ™ºèƒ½ä½“åŠ¨æ€åœ°è°ƒæ•´å…¶è®¡åˆ’ã€ä¿®æ­£é”™è¯¯ï¼Œå¹¶å®ç°éœ€è¦ä¸ç¯å¢ƒè¿›è¡Œå¤šæ¬¡äº¤äº’çš„ç›®æ ‡ã€‚ç”±äºæ™ºèƒ½ä½“å¯¹å®æ—¶åé¦ˆä½œå‡ºå“åº”ï¼Œå› æ­¤ä¸çº¿æ€§ CoT ç›¸æ¯”ï¼Œè¿™æä¾›äº†ä¸€ç§æ›´ç¨³å¥å’Œçµæ´»çš„é—®é¢˜è§£å†³æ–¹æ³•ã€‚é€šè¿‡å°†è¯­è¨€æ¨¡å‹çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ä¸ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ç›¸ç»“åˆï¼ŒReAct ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ‰§è¡Œæ—¢éœ€è¦æ¨ç†åˆéœ€è¦å®é™…æ‰§è¡Œçš„å¤æ‚ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•å¯¹æ™ºèƒ½ä½“è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä½¿æ™ºèƒ½ä½“ä¸ä»…èƒ½å¤Ÿæ¨ç†ï¼Œè¿˜èƒ½å®é™…æ‰§è¡Œæ­¥éª¤å¹¶ä¸åŠ¨æ€ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚</mark>

**CoD** (Chain of Debates) is a formal AI framework proposed by Microsoft where multiple, diverse models collaborate and argue to solve a problem, moving beyond a single AI's "chain of thought." This system operates like an AI council meeting, where different models present initial ideas, critique each other's reasoning, and exchange counterarguments. The primary goal is to enhance accuracy, reduce bias, and improve the overall quality of the final answer by leveraging collective intelligence. Functioning as an AI version of peer review, this method creates a transparent and trustworthy record of the reasoning process. Ultimately, it represents a shift from a solitary Agent providing an answer to a collaborative team of Agents working together to find a more robust and validated solution.

<mark>**CoD**ï¼ˆè¾©è®ºé“¾ï¼ŒChain of Debatesï¼‰æ˜¯å¾®è½¯æå‡ºçš„ä¸€ç§æ­£å¼ AI æ¡†æ¶ï¼Œå…¶ä¸­å¤šä¸ªã€ä¸åŒçš„æ¨¡å‹ååŒåˆä½œå¹¶è¿›è¡Œè¾©è®ºæ¥è§£å†³é—®é¢˜ï¼Œè¶…è¶Šäº†å•ä¸ª AI çš„ã€Œæ€ç»´é“¾ã€ã€‚è¯¥ç³»ç»Ÿè¿ä½œèµ·æ¥å°±åƒä¸€ä¸ª AI å§”å‘˜ä¼šä¼šè®®ï¼Œä¸åŒçš„æ¨¡å‹æå‡ºåˆå§‹æƒ³æ³•ã€æ‰¹åˆ¤å½¼æ­¤çš„æ¨ç†ï¼Œå¹¶äº¤æ¢åé©³æ„è§ã€‚å…¶ä¸»è¦ç›®æ ‡æ˜¯é€šè¿‡åˆ©ç”¨é›†ä½“æ™ºæ…§ï¼Œæé«˜æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€å‡å°‘åè§å¹¶æ”¹å–„æ•´ä½“è´¨é‡ã€‚è¯¥æ–¹æ³•å……å½“ AI ç‰ˆçš„åŒè¡Œè¯„å®¡ï¼Œåˆ›å»ºäº†ä¸€ä¸ªé€æ˜ä¸”å€¼å¾—ä¿¡èµ–çš„æ¨ç†è¿‡ç¨‹è®°å½•ã€‚æœ€ç»ˆï¼Œå®ƒä»£è¡¨äº†ä¸€ç§è½¬å˜ï¼Œå³ä»ä¸€ä¸ªå•ç‹¬çš„æ™ºèƒ½ä½“æä¾›ç­”æ¡ˆï¼Œè½¬å‘ä¸€ä¸ªæ™ºèƒ½ä½“åä½œå›¢é˜Ÿå…±åŒå¯»æ‰¾ä¸€ä¸ªæ›´ç¨³å¥ã€ç»è¿‡éªŒè¯çš„è§£å†³æ–¹æ¡ˆã€‚</mark>

GoD (Graph of Debates) is an advanced Agentic framework that reimagines discussion as a dynamic, non-linear network rather than a simple chain. In this model, arguments are individual nodes connected by edges that signify relationships like 'supports' or 'refutes,' reflecting the multi-threaded nature of real debate. This structure allows new lines of inquiry to dynamically branch off, evolve independently, and even merge over time. A conclusion is reached not at the end of a sequence, but by identifying the most robust and well-supported cluster of arguments within the entire graph. In this context, "well-supported" refers to knowledge that is firmly established and verifiable. This can include information considered to be ground truth, which means it is inherently correct and widely accepted as fact. Additionally, it encompasses factual evidence obtained through search grounding, where information is validated against external sources and real-world data. Finally, it also pertains to a consensus reached by multiple models during a debate, indicating a high degree of agreement and confidence in the information presented. This comprehensive approach ensures a more robust and reliable foundation for the information being discussed. This approach provides a more holistic and realistic model for complex, collaborative AI reasoning.

<mark>GoDï¼ˆè¾©è®ºå›¾ï¼ŒGraph of Debatesï¼‰æ˜¯ä¸€ç§å…ˆè¿›çš„å…·æ™ºèƒ½ä½“ç‰¹æ€§ï¼ˆAgenticï¼‰æ¡†æ¶ï¼Œå®ƒå°†è®¨è®ºé‡æ–°æ„æƒ³ä¸ºä¸€ä¸ªåŠ¨æ€ã€éçº¿æ€§çš„ç½‘ç»œï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç®€å•çš„é“¾æ¡ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œè®ºç‚¹æ˜¯å•ç‹¬çš„èŠ‚ç‚¹ï¼Œé€šè¿‡è¡¨ç¤ºã€Œæ”¯æŒã€æˆ–ã€Œåé©³ã€ç­‰å…³ç³»çš„è¾¹è¿æ¥èµ·æ¥ï¼Œåæ˜ äº†çœŸå®è¾©è®ºçš„å¤šçº¿ç¨‹ç‰¹æ€§ã€‚è¿™ç§ç»“æ„å…è®¸æ–°çš„æ¢ç©¶è·¯çº¿åŠ¨æ€åœ°åˆ†æ”¯å‡ºæ¥ã€ç‹¬ç«‹æ¼”åŒ–ï¼Œç”šè‡³éšæ—¶é—´æ¨ç§»è€Œåˆå¹¶ã€‚ç»“è®ºçš„å¾—å‡ºå¹¶éåœ¨åºåˆ—çš„æœ«å°¾ï¼Œè€Œæ˜¯é€šè¿‡è¯†åˆ«æ•´ä¸ªå›¾ä¸­æœ€ç¨³å¥å’Œå¾—åˆ°å……åˆ†æ”¯æŒçš„è®ºç‚¹é›†ç¾¤ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œã€Œå¾—åˆ°å……åˆ†æ”¯æŒã€æŒ‡çš„æ˜¯åšå®šç¡®ç«‹ä¸”å¯éªŒè¯çš„çŸ¥è¯†ã€‚è¿™å¯ä»¥åŒ…æ‹¬è¢«è®¤ä¸ºæ˜¯åŸºç¡€äº‹å®ï¼ˆground truthï¼‰çš„ä¿¡æ¯ï¼Œå³å…¶æœ¬è´¨ä¸Šæ­£ç¡®å¹¶è¢«å¹¿æ³›æ¥å—ä¸ºäº‹å®ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åŒ…æ‹¬é€šè¿‡æœç´¢æº¯æºï¼ˆsearch groundingï¼‰è·å¾—çš„äº‹å®è¯æ®ï¼Œå³ä¿¡æ¯å·²æ ¹æ®å¤–éƒ¨æ¥æºå’ŒçœŸå®ä¸–ç•Œæ•°æ®è¿›è¡Œäº†éªŒè¯ã€‚æœ€åï¼Œå®ƒä¹Ÿæ¶‰åŠå¤šä¸ªæ¨¡å‹åœ¨è¾©è®ºä¸­è¾¾æˆçš„å…±è¯†ï¼Œè¡¨æ˜å¯¹æ‰€å‘ˆç°ä¿¡æ¯çš„é«˜åº¦ä¸€è‡´æ€§å’Œä¿¡å¿ƒã€‚è¿™ç§ç»¼åˆæ–¹æ³•ç¡®ä¿äº†æ‰€è®¨è®ºä¿¡æ¯å…·æœ‰æ›´ç¨³å¥å’Œå¯é çš„åŸºç¡€ã€‚è¿™ç§æ–¹æ³•ä¸ºå¤æ‚ã€åä½œçš„ AI æ¨ç†æä¾›äº†ä¸€ä¸ªæ›´æ•´ä½“ã€æ›´çœŸå®çš„æ¨¡å‹ã€‚</mark>

**MASS (optional advanced topic):** An in-depth analysis of the design of multi-agent systems reveals that their effectiveness is critically dependent on both the quality of the prompts used to program individual agents and the topology that dictates their interactions. The complexity of designing these systems is significant, as it involves a vast and intricate search space. To address this challenge, a novel framework called Multi-Agent System Search (MASS) was developed to automate and optimize the design of MAS.

<mark>**MASSï¼ˆå¯é€‰è¿›é˜¶ä¸»é¢˜ï¼‰ï¼š** å¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Systems, MASï¼‰è®¾è®¡çš„æ·±å…¥åˆ†æè¡¨æ˜ï¼Œå…¶æœ‰æ•ˆæ€§å…³é”®å–å†³äºç”¨äºç¼–ç¨‹å•ä¸ªæ™ºèƒ½ä½“çš„æç¤ºï¼ˆPromptï¼‰è´¨é‡ä»¥åŠå†³å®šå…¶äº¤äº’çš„æ‹“æ‰‘ç»“æ„ã€‚è®¾è®¡è¿™äº›ç³»ç»Ÿçš„å¤æ‚æ€§éå¸¸é«˜ï¼Œå› ä¸ºå®ƒæ¶‰åŠä¸€ä¸ªåºå¤§è€Œé”™ç»¼å¤æ‚çš„æœç´¢ç©ºé—´ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå¼€å‘äº†ä¸€ä¸ªåä¸º**å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæœç´¢ï¼ˆMASSï¼‰**çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨åŒ–å’Œä¼˜åŒ– MAS çš„è®¾è®¡ã€‚</mark>

MASS employs a multi-stage optimization strategy that systematically navigates the complex design space by interleaving prompt and topology optimization (see Fig. 4)

<mark>MASS é‡‡ç”¨ä¸€ç§å¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡äº¤é”™è¿›è¡Œæç¤ºä¼˜åŒ–å’Œæ‹“æ‰‘ä¼˜åŒ–ï¼Œç³»ç»Ÿåœ°å¯¼èˆªå¤æ‚çš„è®¾è®¡ç©ºé—´ï¼ˆå‚è§å›¾ 4ï¼‰ã€‚</mark>

**1. Block-Level Prompt Optimization:** The process begins with a local optimization of prompts for individual agent types, or "blocks," to ensure each component performs its role effectively before being integrated into a larger system. This initial step is crucial as it ensures that the subsequent topology optimization builds upon well-performing agents, rather than suffering from the compounding impact of poorly configured ones. For example, when optimizing for the HotpotQA dataset, the prompt for a "Debator" agent is creatively framed to instruct it to act as an "expert fact-checker for a major publication". Its optimized task is to meticulously review proposed answers from other agents, cross-reference them with provided context passages, and identify any inconsistencies or unsupported claims. This specialized role-playing prompt, discovered during block-level optimization, aims to make the debator agent highly effective at synthesizing information before it's even placed into a larger workflow.

<mark>**1. å—çº§æç¤ºä¼˜åŒ–ï¼ˆBlock-Level Prompt Optimizationï¼‰ï¼š** è¯¥è¿‡ç¨‹ä»å¯¹å•ä¸ªæ™ºèƒ½ä½“ç±»å‹æˆ–ã€Œå—ã€çš„æç¤ºè¿›è¡Œå±€éƒ¨ä¼˜åŒ–å¼€å§‹ï¼Œä»¥ç¡®ä¿æ¯ä¸ªç»„ä»¶åœ¨é›†æˆåˆ°æ›´å¤§ç³»ç»Ÿä¹‹å‰éƒ½èƒ½æœ‰æ•ˆåœ°æ‰§è¡Œå…¶è§’è‰²ã€‚è¿™ä¸€åˆå§‹æ­¥éª¤è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒèƒ½ç¡®ä¿åç»­çš„æ‹“æ‰‘ä¼˜åŒ–æ˜¯å»ºç«‹åœ¨è¡¨ç°è‰¯å¥½çš„æ™ºèƒ½ä½“ä¹‹ä¸Šçš„ï¼Œè€Œä¸æ˜¯å› é…ç½®ä¸ä½³çš„æ™ºèƒ½ä½“è€Œé­å—å¤åˆå½±å“ã€‚ä¾‹å¦‚ï¼Œåœ¨é’ˆå¯¹ HotpotQA æ•°æ®é›†è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œã€Œè¾©è®ºè€…ã€æ™ºèƒ½ä½“çš„æç¤ºè¢«åˆ›é€ æ€§åœ°æ„æ€ï¼ŒæŒ‡ç¤ºå…¶æ‰®æ¼”**ã€ŒæŸä¸»è¦å‡ºç‰ˆç‰©çš„ä¸“å®¶äº‹å®æ ¸æŸ¥å‘˜ã€ã€‚å…¶ä¼˜åŒ–åçš„ä»»åŠ¡æ˜¯ä»”ç»†å®¡æŸ¥å…¶ä»–æ™ºèƒ½ä½“æå‡ºçš„ç­”æ¡ˆï¼Œå°†å…¶ä¸æä¾›çš„ä¸Šä¸‹æ–‡æ®µè½è¿›è¡Œäº¤å‰å¼•ç”¨ï¼Œå¹¶è¯†åˆ«ä»»ä½•ä¸ä¸€è‡´æˆ–æœªå¾—åˆ°æ”¯æŒçš„è®ºæ–­ã€‚è¿™ä¸ªåœ¨å—çº§ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç°çš„ä¸“ä¸šè§’è‰²æ‰®æ¼”æç¤º**ï¼Œæ—¨åœ¨ä½¿è¾©è®ºè€…æ™ºèƒ½ä½“åœ¨è¢«æ”¾å…¥æ›´å¤§å·¥ä½œæµä¹‹å‰ï¼Œå°±èƒ½é«˜æ•ˆåœ°ç»¼åˆä¿¡æ¯ã€‚</mark>

**2. Workflow Topology Optimization:** Following local optimization, MASS optimizes the workflow topology by selecting and arranging different agent interactions from a customizable design space. To make this search efficient, MASS employs an influence-weighted method. This method calculates the "incremental influence" of each topology by measuring its performance gain relative to a baseline agent and uses these scores to guide the search toward more promising combinations. For instance, when optimizing for the MBPP coding task, the topology search discovers that a specific hybrid workflow is most effective. The best-found topology is not a simple structure but a combination of an iterative refinement process with external tool use. Specifically, it consists of one predictor agent that engages in several rounds of reflection, with its code being verified by one executor agent that runs the code against test cases. This discovered workflow shows that for coding, a structure that combines iterative self-correction with external verification is superior to simpler MAS designs.

<mark>**2. å·¥ä½œæµæ‹“æ‰‘ä¼˜åŒ–ï¼ˆWorkflow Topology Optimizationï¼‰ï¼š** åœ¨å±€éƒ¨ä¼˜åŒ–ä¹‹åï¼ŒMASS é€šè¿‡ä»å¯å®šåˆ¶çš„è®¾è®¡ç©ºé—´ä¸­é€‰æ‹©å’Œæ’åˆ—ä¸åŒçš„æ™ºèƒ½ä½“äº¤äº’ï¼Œæ¥ä¼˜åŒ–å·¥ä½œæµæ‹“æ‰‘ã€‚ä¸ºäº†æé«˜æœç´¢æ•ˆç‡ï¼ŒMASS é‡‡ç”¨äº†ä¸€ç§å½±å“åŠ æƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æµ‹é‡æ¯ç§æ‹“æ‰‘ç»“æ„ç›¸å¯¹äºåŸºçº¿æ™ºèƒ½ä½“çš„æ€§èƒ½å¢ç›Šï¼Œè®¡ç®—å…¶ã€Œå¢é‡å½±å“ã€ï¼Œå¹¶ä½¿ç”¨è¿™äº›åˆ†æ•°æ¥æŒ‡å¯¼æœç´¢ï¼Œä½¿å…¶å€¾å‘äºæ›´æœ‰å‰é€”çš„ç»„åˆã€‚ä¾‹å¦‚ï¼Œåœ¨é’ˆå¯¹ MBPP ç¼–ç ä»»åŠ¡è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œæ‹“æ‰‘æœç´¢å‘ç°ç‰¹å®šçš„æ··åˆå·¥ä½œæµæœ€ä¸ºæœ‰æ•ˆã€‚å‘ç°çš„æœ€ä½³æ‹“æ‰‘ç»“æ„å¹¶éä¸€ä¸ªç®€å•çš„ç»“æ„ï¼Œè€Œæ˜¯è¿­ä»£ç²¾ç‚¼è¿‡ç¨‹ä¸å¤–éƒ¨å·¥å…·ä½¿ç”¨çš„ç»„åˆã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåŒ…å«ä¸€ä¸ªè¿›è¡Œå¤šè½®åæ€çš„é¢„æµ‹æ™ºèƒ½ä½“ï¼Œå…¶ä»£ç ç”±ä¸€ä¸ªé’ˆå¯¹æµ‹è¯•ç”¨ä¾‹è¿è¡Œä»£ç çš„æ‰§è¡Œæ™ºèƒ½ä½“è¿›è¡ŒéªŒè¯ã€‚è¿™ä¸ªè¢«å‘ç°çš„å·¥ä½œæµè¡¨æ˜ï¼Œå¯¹äºç¼–ç ä»»åŠ¡ï¼Œå°†è¿­ä»£è‡ªæˆ‘ä¿®æ­£ä¸å¤–éƒ¨éªŒè¯ç›¸ç»“åˆçš„ç»“æ„ä¼˜äºæ›´ç®€å•çš„ MAS è®¾è®¡ã€‚</mark>

<img width="1356" height="542" alt="image" src="https://github.com/user-attachments/assets/f98f633b-dced-479d-bc52-d57ad6e5a992" />
Fig. 4: (Courtesy of the Authors): The Multi-Agent System Search (MASS) Framework is a three-stage optimization process that navigates a search space encompassing optimizable prompts (instructions and demonstrations) and configurable agent building blocks (Aggregate, Reflect, Debate, Summarize, and Tool-use). The first stage, Block-level Prompt Optimization, independently optimizes prompts for each agent module. Stage two, Workflow Topology Optimization, samples valid system configurations from an influence-weighted design space, integrating the optimized prompts. The final stage, Workflow-level Prompt Optimization, involves a second round of prompt optimization for the entire multi-agent system after the optimal workflow from Stage two has been identified.

<mark>å›¾ 4ï¼šï¼ˆä½œè€…ä¾›å›¾ï¼‰ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæœç´¢ï¼ˆMulti-Agent System Search, MASSï¼‰æ¡†æ¶æ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µçš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œå®ƒåœ¨ä¸€ä¸ªåŒ…å«å¯ä¼˜åŒ–æç¤ºï¼ˆæŒ‡ä»¤å’Œæ¼”ç¤ºï¼‰å’Œå¯é…ç½®æ™ºèƒ½ä½“æ„å»ºæ¨¡å—ï¼ˆèšåˆã€åæ€ã€è¾©è®ºã€æ€»ç»“å’Œå·¥å…·ä½¿ç”¨ï¼‰çš„æœç´¢ç©ºé—´ä¸­è¿›è¡Œå¯¼èˆªã€‚ç¬¬ä¸€é˜¶æ®µï¼Œå—çº§æç¤ºä¼˜åŒ–ï¼Œç‹¬ç«‹ä¼˜åŒ–æ¯ä¸ªæ™ºèƒ½ä½“æ¨¡å—çš„æç¤ºã€‚ç¬¬äºŒé˜¶æ®µï¼Œå·¥ä½œæµæ‹“æ‰‘ä¼˜åŒ–ï¼Œä»å½±å“åŠ æƒçš„è®¾è®¡ç©ºé—´ä¸­é‡‡æ ·æœ‰æ•ˆçš„ç³»ç»Ÿé…ç½®ï¼Œå¹¶æ•´åˆä¼˜åŒ–åçš„æç¤ºã€‚æœ€ç»ˆé˜¶æ®µï¼Œå·¥ä½œæµçº§æç¤ºä¼˜åŒ–ï¼Œåœ¨ç¡®å®šç¬¬äºŒé˜¶æ®µçš„æœ€ä½³å·¥ä½œæµä¹‹åï¼Œå¯¹æ•´ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿›è¡Œç¬¬äºŒè½®æç¤ºä¼˜åŒ–ã€‚</mark>

**3. Workflow-Level Prompt Optimization:** The final stage involves a global optimization of the entire system's prompts. After identifying the best-performing topology, the prompts are fine-tuned as a single, integrated entity to ensure they are tailored for orchestration and that agent interdependencies are optimized. As an example, after finding the best topology for the DROP dataset, the final optimization stage refines the "Predictor" agent's prompt. The final, optimized prompt is highly detailed, beginning by providing the agent with a summary of the dataset itself, noting its focus on "extractive question answering" and "numerical information". It then includes few-shot examples of correct question-answering behavior and frames the core instruction as a high-stakes scenario: "You are a highly specialized AI tasked with extracting critical numerical information for an urgent news report. A live broadcast is relying on your accuracy and speed". This multi-faceted prompt, combining meta-knowledge, examples, and role-playing, is tuned specifically for the final workflow to maximize accuracy. 

<mark>** 3. å·¥ä½œæµçº§æç¤ºä¼˜åŒ–ï¼ˆWorkflow-Level Prompt Optimizationï¼‰ï¼š** æœ€ç»ˆé˜¶æ®µæ¶‰åŠå¯¹æ•´ä¸ªç³»ç»Ÿæç¤ºçš„å…¨å±€ä¼˜åŒ–ã€‚åœ¨è¯†åˆ«å‡ºæ€§èƒ½æœ€ä½³çš„æ‹“æ‰‘ç»“æ„åï¼Œå°†æç¤ºä½œä¸ºå•ä¸€ã€é›†æˆçš„å®ä½“è¿›è¡Œå¾®è°ƒï¼Œä»¥ç¡®ä¿å®ƒä»¬é€‚åº”ç¼–æ’ï¼Œå¹¶ä¼˜åŒ–æ™ºèƒ½ä½“ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚ä¾‹å¦‚ï¼Œåœ¨æ‰¾åˆ° DROP æ•°æ®é›†çš„æœ€ä½³æ‹“æ‰‘ç»“æ„åï¼Œæœ€ç»ˆä¼˜åŒ–é˜¶æ®µä¼šç²¾ç‚¼**ã€Œé¢„æµ‹æ™ºèƒ½ä½“ã€ï¼ˆ"Predictor" agentï¼‰çš„æç¤ºã€‚æœ€ç»ˆä¼˜åŒ–åçš„æç¤ºé«˜åº¦è¯¦ç»†**ï¼Œé¦–å…ˆå‘æ™ºèƒ½ä½“æä¾›æ•°æ®é›†æœ¬èº«çš„æ‘˜è¦ï¼ŒæŒ‡å‡ºå…¶ä¾§é‡äº**ã€ŒæŠ½å–å¼é—®ç­”ã€ï¼ˆ"extractive question answering"ï¼‰å’Œã€Œæ•°å€¼ä¿¡æ¯ã€ï¼ˆ"numerical information"ï¼‰ã€‚ç„¶åï¼Œå®ƒåŒ…å«å°‘é‡ç¤ºä¾‹**ï¼ˆfew-shot examplesï¼‰ï¼Œå±•ç¤ºæ­£ç¡®çš„é—®ç­”è¡Œä¸ºï¼Œå¹¶å°†æ ¸å¿ƒæŒ‡ä»¤æ¡†å®šä¸ºä¸€ä¸ªé«˜é£é™©åœºæ™¯ï¼šã€Œä½ æ˜¯ä¸€ä¸ªé«˜åº¦ä¸“ä¸šåŒ–çš„ AIï¼Œä»»åŠ¡æ˜¯ä¸ºä¸€ç¯‡ç´§æ€¥æ–°é—»æŠ¥é“æå–å…³é”®çš„æ•°å€¼ä¿¡æ¯ã€‚ä¸€æ¬¡ç°åœºç›´æ’­æ­£ä¾èµ–ä½ çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€ã€‚è¿™ç§ç»“åˆäº†å…ƒçŸ¥è¯†ã€ç¤ºä¾‹å’Œè§’è‰²æ‰®æ¼”çš„å¤šæ–¹é¢æç¤ºï¼Œæ˜¯ä¸“é—¨é’ˆå¯¹æœ€ç»ˆå·¥ä½œæµè¿›è¡Œè°ƒä¼˜çš„ï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜å‡†ç¡®æ€§ã€‚</mark>

Key Findings and Principles: Experiments demonstrate that MAS optimized by MASS significantly outperform existing manually designed systems and other automated design methods across a range of tasks. The key design principles for effective MAS, as derived from this research, are threefold:

<mark>å…³é”®å‘ç°ä¸åŸåˆ™ï¼š å®éªŒè¯æ˜ï¼Œç» MASS ä¼˜åŒ–çš„ MAS åœ¨ä¸€ç³»åˆ—ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æ‰‹åŠ¨è®¾è®¡çš„ç³»ç»Ÿå’Œå…¶ä»–è‡ªåŠ¨åŒ–è®¾è®¡æ–¹æ³•ã€‚æ ¹æ®è¿™é¡¹ç ”ç©¶å¾—å‡ºçš„æœ‰æ•ˆ MAS çš„å…³é”®è®¾è®¡åŸåˆ™æœ‰ä¸‰ç‚¹ï¼š</mark>

  * Optimize individual agents with high-quality prompts before composing them.
  * Construct MAS by composing influential topologies rather than exploring an unconstrained search space.
  * Model and optimize the interdependencies between agents through a final, workflow-level joint optimization.

<mark>
  * åœ¨ç»„åˆæ™ºèƒ½ä½“ä¹‹å‰ï¼Œä½¿ç”¨é«˜è´¨é‡çš„æç¤ºæ¥ä¼˜åŒ–å•ä¸ªæ™ºèƒ½ä½“ã€‚
  * é€šè¿‡ç»„åˆæœ‰å½±å“åŠ›çš„æ‹“æ‰‘ç»“æ„æ¥æ„å»º MASï¼Œè€Œä¸æ˜¯æ¢ç´¢æ— çº¦æŸçš„æœç´¢ç©ºé—´ã€‚
  * é€šè¿‡æœ€ç»ˆçš„å·¥ä½œæµçº§è”åˆä¼˜åŒ–ï¼Œå¯¹æ™ºèƒ½ä½“ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡å’Œä¼˜åŒ–ã€‚</mark>

Building on our discussion of key reasoning techniques, let's first examine a core performance principle: the Scaling Inference Law for LLMs. This law states that a model's performance predictably improves as the computational resources allocated to it increase. We can see this principle in action in complex systems like Deep Research, where an AI agent leverages these resources to autonomously investigate a topic by breaking it down into sub-questions, using Web search as a tool, and synthesizing its findings.

<mark>åœ¨æˆ‘ä»¬è®¨è®ºäº†å…³é”®æ¨ç†æŠ€å·§ä¹‹åï¼Œé¦–å…ˆè®©æˆ‘ä»¬è€ƒå¯Ÿä¸€ä¸ªæ ¸å¿ƒæ€§èƒ½åŸåˆ™ï¼šLLM çš„æ¨ç†æ‰©å±•å®šå¾‹ï¼ˆScaling Inference Law for LLMsï¼‰ã€‚è¯¥å®šå¾‹æŒ‡å‡ºï¼Œéšç€åˆ†é…ç»™æ¨¡å‹çš„è®¡ç®—èµ„æºå¢åŠ ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šå¯é¢„æµ‹åœ°æé«˜ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨åƒæ·±åº¦ç ”ç©¶ï¼ˆDeep Researchï¼‰è¿™æ ·çš„å¤æ‚ç³»ç»Ÿä¸­ï¼Œè¿™ä¸ªåŸåˆ™æ­£åœ¨å‘æŒ¥ä½œç”¨ï¼ŒAI æ™ºèƒ½ä½“åˆ©ç”¨è¿™äº›èµ„æºè‡ªä¸»è°ƒæŸ¥ä¸€ä¸ªä¸»é¢˜ï¼šå°†å…¶åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œä½¿ç”¨ Web æœç´¢ä½œä¸ºå·¥å…·ï¼Œå¹¶ç»¼åˆå…¶å‘ç°ã€‚</mark>

**Deep Research.** The term "Deep Research" describes a category of AI Agentic tools designed to act as tireless, methodical research assistants. Major platforms in this space include Perplexity AI, Google's Gemini research capabilities, and OpenAI's advanced functions within ChatGPT (see Fig.5).

<mark>** æ·±åº¦ç ”ç©¶ï¼ˆDeep Researchï¼‰ã€‚** ã€Œæ·±åº¦ç ”ç©¶ã€ä¸€è¯æè¿°äº†ä¸€ç±»å…·æ™ºèƒ½ä½“ç‰¹æ€§ï¼ˆAgenticï¼‰çš„ AI å·¥å…·ï¼Œå®ƒä»¬æ—¨åœ¨å……å½“ä¸çŸ¥ç–²å€¦ã€æœ‰æ¡ä¸ç´Šçš„ç ”ç©¶åŠ©ç†ã€‚è¯¥é¢†åŸŸçš„ä¸»è¦å¹³å°åŒ…æ‹¬ Perplexity AIã€Google Gemini çš„ç ”ç©¶èƒ½åŠ›ä»¥åŠ OpenAI ChatGPT å†…éƒ¨çš„é«˜çº§åŠŸèƒ½ï¼ˆå‚è§å›¾ 5ï¼‰ã€‚</mark>

<img width="1314" height="1402" alt="image" src="https://github.com/user-attachments/assets/a475f47d-69c3-4dd7-8e8b-2827e1d0f17d" />

Fig. 5: Google Deep Research for Information Gathering
<mark>å›¾ 5ï¼šç”¨äºä¿¡æ¯æ”¶é›†çš„ Google Deep Research</mark>

A fundamental shift introduced by these tools is the change in the search process itself. A standard search provides immediate links, leaving the work of synthesis to you. Deep Research operates on a different model. Here, you task an AI with a complex query and grant it a "time budget"â€”usually a few minutes. In return for this patience, you receive a detailed report.

<mark>è¿™äº›å·¥å…·å¸¦æ¥çš„ä¸€ä¸ªæ ¹æœ¬æ€§è½¬å˜æ˜¯æœç´¢è¿‡ç¨‹æœ¬èº«çš„æ”¹å˜ã€‚æ ‡å‡†æœç´¢ä¼šç«‹å³æä¾›é“¾æ¥ï¼Œå°†ç»¼åˆæ•´ç†çš„å·¥ä½œç•™ç»™ä½ ã€‚è€Œæ·±åº¦ç ”ç©¶åˆ™é‡‡ç”¨ä¸åŒçš„æ¨¡å¼ã€‚åœ¨è¿™é‡Œï¼Œä½ ç»™ AI åˆ†é…ä¸€ä¸ªå¤æ‚çš„æŸ¥è¯¢ä»»åŠ¡ï¼Œå¹¶æˆäºˆå®ƒä¸€ä¸ªã€Œæ—¶é—´é¢„ç®—ã€â€”â€”é€šå¸¸æ˜¯å‡ åˆ†é’Ÿã€‚ä½œä¸ºè¿™ç§è€å¿ƒçš„å›æŠ¥ï¼Œä½ å°†æ”¶åˆ°ä¸€ä»½è¯¦ç»†çš„æŠ¥å‘Šã€‚</mark>

During this time, the AI works on your behalf in an agentic way. It autonomously performs a series of sophisticated steps that would be incredibly time-consuming for a person:

<mark>åœ¨æ­¤æœŸé—´ï¼ŒAI ä»¥ä¸€ç§å…·æ™ºèƒ½ä½“ç‰¹æ€§çš„æ–¹å¼ä¸ºä½ å·¥ä½œã€‚å®ƒè‡ªä¸»æ‰§è¡Œä¸€ç³»åˆ—å¤æ‚ä¸”å¯¹äººæ¥è¯´æå…¶è€—æ—¶çš„æ­¥éª¤ï¼š</mark>

1. Initial Exploration: It runs multiple, targeted searches based on your initial prompt.

<mark>1. åˆå§‹æ¢ç´¢ï¼š å®ƒæ ¹æ®ä½ çš„åˆå§‹æç¤ºè¿è¡Œå¤šä¸ªæœ‰é’ˆå¯¹æ€§çš„æœç´¢ã€‚</mark>

2. Reasoning and Refinement: It reads and analyzes the first wave of results, synthesizes the findings, and critically identifies gaps, contradictions, or areas that require more detail.

<mark>2. æ¨ç†ä¸ç²¾ç‚¼ï¼š å®ƒé˜…è¯»å’Œåˆ†æç¬¬ä¸€æ³¢ç»“æœï¼Œç»¼åˆå…¶å‘ç°ï¼Œå¹¶æ‰¹åˆ¤æ€§åœ°è¯†åˆ«å‡ºç©ºç™½ã€çŸ›ç›¾æˆ–éœ€è¦æ›´å¤šç»†èŠ‚çš„é¢†åŸŸã€‚</mark>

3. Follow-up Inquiry: Based on its internal reasoning, it conducts new, more nuanced searches to fill those gaps and deepen its understanding.

<mark>3. åç»­æ¢ç©¶ï¼š åŸºäºå…¶å†…éƒ¨æ¨ç†ï¼Œå®ƒè¿›è¡Œæ–°çš„ã€æ›´ç»†è‡´çš„æœç´¢ï¼Œä»¥å¡«è¡¥è¿™äº›ç©ºç™½å¹¶åŠ æ·±å…¶ç†è§£ã€‚</mark>

4. Final Synthesis: After several rounds of this iterative searching and reasoning, it compiles all the validated information into a single, cohesive, and structured summary.

<mark>4. æœ€ç»ˆç»¼åˆï¼š ç»è¿‡å¤šè½®è¿™ç§è¿­ä»£æœç´¢å’Œæ¨ç†åï¼Œå®ƒå°†æ‰€æœ‰ç»è¿‡éªŒè¯çš„ä¿¡æ¯æ±‡ç¼–æˆä¸€ä¸ªå•ä¸€ã€æœ‰å‡èšåŠ›ä¸”ç»“æ„åŒ–çš„æ‘˜è¦ã€‚</mark>

This systematic approach ensures a comprehensive and well-reasoned response, significantly enhancing the efficiency and depth of information gathering, thereby facilitating more agentic decision-making.

<mark>è¿™ç§ç³»ç»Ÿæ–¹æ³•ç¡®ä¿äº†å…¨é¢ä¸”æœ‰å……åˆ†ç†ç”±æ”¯æŒçš„å“åº”ï¼Œæ˜¾è‘—æé«˜äº†ä¿¡æ¯æ”¶é›†çš„æ•ˆç‡å’Œæ·±åº¦ï¼Œä»è€Œä¿ƒè¿›äº†æ›´å…·æ™ºèƒ½ä½“ç‰¹æ€§çš„å†³ç­–åˆ¶å®šã€‚</mark>
